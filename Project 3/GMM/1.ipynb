{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal \n",
    "\n",
    "class GMM:\n",
    "    def __init__(self, k, max_iter=5):\n",
    "        self.k = k\n",
    "        self.max_iter = int(max_iter) \n",
    "\n",
    "    def initialize(self, X):\n",
    "        # returns the (r,c) value of the numpy array of X\n",
    "        self.shape = X.shape \n",
    "        # n has the number of rows while m has the number of columns of dataset X\n",
    "        self.n, self.m = self.shape \n",
    "        \n",
    "\n",
    "        # initial weights given to each cluster are stored in phi or P(Ci=j)\n",
    "        self.phi = np.full(shape=self.k, fill_value=1/self.k) \n",
    "\n",
    "        # initial weights given to each data point wrt to each cluster or P(Xi/Ci=j)\n",
    "        self.weights = np.full(shape=self.shape, fill_value=1/self.k)\n",
    "        \n",
    "        # dataset is divided randomly into k parts of unequal sizes\n",
    "        random_row = np.random.randint(low=0, high=self.n, size=self.k)\n",
    "\n",
    "        # initial value of mean of k Gaussians\n",
    "        self.mu = [  X[row_index,:] for row_index in random_row ] \n",
    "\n",
    "        # initial value of covariance matrix of k Gaussians\n",
    "        self.sigma = [ np.cov(X.T) for _ in range(self.k) ] \n",
    "        # theta =(mu1,sigma1,mu2,simga2......muk,sigmak)\n",
    "\n",
    "    # E-Step: update weights and phi holding mu and sigma constant\n",
    "    def e_step(self, X):\n",
    "        # updated weights or P(Xi/Ci=j)\n",
    "        self.weights = self.predict_proba(X)\n",
    "        # mean of sum of probability of all data points wrt to one cluster is new updated probability of cluster k or (phi)k\n",
    "        self.phi = self.weights.mean(axis=0)\n",
    "\n",
    "    # M-Step: update meu and sigma holding phi and weights constant\n",
    "    def m_step(self, X):\n",
    "        for i in range(self.k):\n",
    "            weight = self.weights[:, [i]]\n",
    "            total_weight = weight.sum()\n",
    "\n",
    "            self.mu[i] = (X * weight).sum(axis=0) / total_weight\n",
    "            self.sigma[i] = np.cov(X.T,aweights=(weight/total_weight).flatten(), bias=True)\n",
    "\n",
    "    # responsible for clustering the data points correctly\n",
    "    def fit(self, X):\n",
    "        # initialise parameters like weights, phi, meu, sigma of all Gaussians in dataset X\n",
    "        self.initialize(X)\n",
    "        plt.figure(figsize=(16, 25))\n",
    "        for iteration in range(self.max_iter):\n",
    "            # iterate to update the value of P(Xi/Ci=j) and (phi)k\n",
    "            self.e_step(X)\n",
    "            # iterate to update the value of meu and sigma as the clusters shift\n",
    "            self.m_step(X)\n",
    "            \n",
    "\n",
    "    # predicts probability of each data point wrt each cluster\n",
    "    def predict_proba(self, X):\n",
    "        # Creates a n*k matrix denoting probability of each point wrt each cluster \n",
    "        likelihood = np.zeros( (self.n, self.k) ) \n",
    "        for i in range(self.k):\n",
    "            distribution = multivariate_normal(mean=self.mu[i],cov=self.sigma[i])\n",
    "            # pdf : probability denisty function\n",
    "            likelihood[:,i] = distribution.pdf(X) \n",
    "\n",
    "        numerator = likelihood * self.phi\n",
    "        denominator = numerator.sum(axis=1)[:, np.newaxis]\n",
    "        weights = numerator / denominator\n",
    "        return weights\n",
    "    \n",
    "    # predict function \n",
    "    def predict(self, X):\n",
    "        weights = self.predict_proba(X)\n",
    "        # datapoint belongs to cluster with maximum probability\n",
    "        # returns this value\n",
    "        return np.argmax(weights, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.826</td>\n",
       "      <td>4.7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-12.301</td>\n",
       "      <td>-1.3551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.968</td>\n",
       "      <td>4.3138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.898</td>\n",
       "      <td>5.3077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.690</td>\n",
       "      <td>5.9609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x       y\n",
       "0 -13.826  4.7990\n",
       "1 -12.301 -1.3551\n",
       "2 -13.968  4.3138\n",
       "3 -13.898  5.3077\n",
       "4 -12.690  5.9609"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "X = []\n",
    "Y = []\n",
    "with open(\"6/train.txt\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        X.append([float(row[0]), float(row[1])])\n",
    "        Y.append([int(row[2])])\n",
    "\n",
    "df = pd.DataFrame(X, columns = ['x', 'y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "gmm = GMM(k=2, max_iter=14)\n",
    "gmm.fit(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy :  89.36 %\n"
     ]
    }
   ],
   "source": [
    "true = 0;\n",
    "X_train = np.array(X)\n",
    "Y_train = np.array(Y)\n",
    "preds = gmm.predict(X)\n",
    "for i in range(len(X_train)):\n",
    "    x = X_train[i];\n",
    "    y = Y_train[i];\n",
    "    if(y == preds[i] + 1):\n",
    "        true += 1\n",
    "print(\" Accuracy : \", true*100/len(X_train), \"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94ae5e5b5ae5a1ee57a607c9497711b6bf7cc4fc8b73b07c0408939ea9c64789"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
