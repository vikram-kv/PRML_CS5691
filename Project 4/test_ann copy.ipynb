{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ANN import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.colors as mcol\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm.notebook import tqdm_notebook as pbar\n",
    "from ldamodule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akkuracy(model, data_x, data_y):\n",
    "    # data_x and data_y are numpy array-of-arrays matrices\n",
    "    X = T.Tensor(data_x).cuda()\n",
    "    Y = T.ByteTensor(data_y).cuda()   # a Tensor of 0s and 1s\n",
    "    oupt = model(X)            # a Tensor of floats\n",
    "    pred_y = oupt >= 0.5       # a Tensor of 0s and 1s\n",
    "    num_correct = T.sum(Y==pred_y)  # a Tensor\n",
    "    acc = (num_correct.item() * 100.0 / len(data_y))  # scalar\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14.43596479]\n",
      " [-11.89816723]\n",
      " [-14.4943825 ]\n",
      " ...\n",
      " [ -9.33195497]\n",
      " [ -5.28588289]\n",
      " [ -8.00972282]]\n"
     ]
    }
   ],
   "source": [
    "# io train\n",
    "X = []\n",
    "Y = []\n",
    "with open(\"synthetic_dataset/train.txt\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        X.append([float(row[0]), float(row[1])])\n",
    "        Y.append([int(row[2])-1])\n",
    "                \n",
    "# PredictorScaler=StandardScaler()\n",
    "# X = PredictorScaler.fit_transform(X)\n",
    "X = np.array(X, dtype=np.float64)\n",
    "Y = np.array(Y, dtype=np.float64)\n",
    "\n",
    "ldamachine = FDA(X,[x for [x] in Y],1)\n",
    "X = ldamachine.get_transformed_data()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14.63084829]\n",
      " [-12.14780725]\n",
      " [ -9.94540319]\n",
      " [ -8.66441229]\n",
      " [-13.2084546 ]\n",
      " [-13.47885705]\n",
      " [-14.17926854]\n",
      " [-13.6876507 ]\n",
      " [-13.99218239]\n",
      " [-13.29742561]\n",
      " [ -8.50677086]\n",
      " [-11.27128925]\n",
      " [-14.08897918]\n",
      " [-11.29634555]\n",
      " [-12.81886485]\n",
      " [-13.0627885 ]\n",
      " [-11.57915313]\n",
      " [-11.62153103]\n",
      " [-13.65013808]\n",
      " [-14.64234353]\n",
      " [-11.15716885]\n",
      " [-13.53446757]\n",
      " [-11.7729434 ]\n",
      " [-11.89256046]\n",
      " [-11.6941462 ]\n",
      " [-10.10595001]\n",
      " [-14.37438939]\n",
      " [-12.51533223]\n",
      " [-14.97671846]\n",
      " [-11.98598769]\n",
      " [-10.78335169]\n",
      " [-14.44931091]\n",
      " [-13.67392721]\n",
      " [-13.15855001]\n",
      " [ -8.08634429]\n",
      " [-13.55561574]\n",
      " [-10.50774156]\n",
      " [-13.54677493]\n",
      " [-12.50468337]\n",
      " [-13.90275527]\n",
      " [-11.22384565]\n",
      " [-13.33145976]\n",
      " [-10.49989284]\n",
      " [-14.6775041 ]\n",
      " [-10.23935402]\n",
      " [ -9.17941751]\n",
      " [-14.17437371]\n",
      " [-14.08613961]\n",
      " [-16.0376873 ]\n",
      " [-12.90398491]\n",
      " [-11.55697516]\n",
      " [-14.58889358]\n",
      " [-10.65359281]\n",
      " [-10.57631046]\n",
      " [-10.07269982]\n",
      " [-12.88157392]\n",
      " [-14.84922361]\n",
      " [-13.74095343]\n",
      " [-14.10526687]\n",
      " [-12.80053237]\n",
      " [-11.17041999]\n",
      " [-13.95199396]\n",
      " [-13.27339028]\n",
      " [-13.18497951]\n",
      " [-12.14952899]\n",
      " [-13.72614255]\n",
      " [ -9.30097534]\n",
      " [-14.97322078]\n",
      " [-11.93298853]\n",
      " [ -9.83067169]\n",
      " [-13.81556543]\n",
      " [-14.07964344]\n",
      " [ -9.61298866]\n",
      " [ -9.66067452]\n",
      " [-13.12565684]\n",
      " [-13.21557132]\n",
      " [-12.27477944]\n",
      " [-14.22937304]\n",
      " [-13.85508253]\n",
      " [-12.09123836]\n",
      " [-10.14477254]\n",
      " [-11.41749354]\n",
      " [-12.17641065]\n",
      " [ -9.88954451]\n",
      " [-10.54924476]\n",
      " [-11.94625892]\n",
      " [-10.1317969 ]\n",
      " [-14.7491365 ]\n",
      " [-12.83399194]\n",
      " [-11.67693198]\n",
      " [-14.17254159]\n",
      " [ -8.66309019]\n",
      " [ -9.3199012 ]\n",
      " [-12.97809131]\n",
      " [ -8.29656127]\n",
      " [-12.30831119]\n",
      " [-14.15777404]\n",
      " [-13.18576949]\n",
      " [-14.08663756]\n",
      " [-14.5595369 ]\n",
      " [ -8.44765821]\n",
      " [-11.16217894]\n",
      " [-11.4791742 ]\n",
      " [-14.98383053]\n",
      " [-13.99203316]\n",
      " [ -8.48359884]\n",
      " [-13.70800365]\n",
      " [-12.97555591]\n",
      " [-13.7713524 ]\n",
      " [ -8.87717157]\n",
      " [-14.15881138]\n",
      " [-14.87818306]\n",
      " [ -6.9661011 ]\n",
      " [ -8.69265674]\n",
      " [-13.34002425]\n",
      " [-12.09744039]\n",
      " [-14.67053942]\n",
      " [-13.96678305]\n",
      " [-14.5245532 ]\n",
      " [-13.26811735]\n",
      " [-13.39792352]\n",
      " [ -8.10094736]\n",
      " [-13.00850791]\n",
      " [-14.00304167]\n",
      " [-14.49112182]\n",
      " [-14.32415246]\n",
      " [-13.65970691]\n",
      " [-12.21308292]\n",
      " [-10.3824447 ]\n",
      " [-12.30522193]\n",
      " [ -8.4211432 ]\n",
      " [-11.94656872]\n",
      " [ -9.82562544]\n",
      " [-14.04523334]\n",
      " [-13.10128734]\n",
      " [-12.95915903]\n",
      " [-12.38114954]\n",
      " [-14.40793941]\n",
      " [-11.97613312]\n",
      " [-12.10678206]\n",
      " [ -7.47017015]\n",
      " [-12.07991571]\n",
      " [-13.16460461]\n",
      " [-11.56213436]\n",
      " [-10.4496718 ]\n",
      " [-13.88401903]\n",
      " [ -7.64053518]\n",
      " [-12.08365844]\n",
      " [-14.38892238]\n",
      " [-14.84741931]\n",
      " [-12.07689402]\n",
      " [-11.62605226]\n",
      " [-11.01245024]\n",
      " [-13.12367657]\n",
      " [-14.13754441]\n",
      " [-13.84309154]\n",
      " [ -8.65501856]\n",
      " [-14.57693675]\n",
      " [-12.21790998]\n",
      " [ -8.96445068]\n",
      " [-11.84908603]\n",
      " [ -8.37416365]\n",
      " [-14.61500863]\n",
      " [-11.12122164]\n",
      " [-11.52784858]\n",
      " [ -9.63231686]\n",
      " [-13.58551051]\n",
      " [-12.55003973]\n",
      " [-13.27241791]\n",
      " [-11.72671954]\n",
      " [-11.90751089]\n",
      " [-14.39391201]\n",
      " [-13.28874018]\n",
      " [-11.34404744]\n",
      " [-12.41051681]\n",
      " [-13.84471912]\n",
      " [ -9.8653318 ]\n",
      " [-13.38301308]\n",
      " [-14.14210535]\n",
      " [-10.90598604]\n",
      " [-14.26528485]\n",
      " [-10.20960161]\n",
      " [-14.27774408]\n",
      " [ -9.55635765]\n",
      " [-12.98753775]\n",
      " [ -8.32995735]\n",
      " [-12.81029654]\n",
      " [-13.2924253 ]\n",
      " [-12.4461814 ]\n",
      " [-13.37489906]\n",
      " [-10.39596768]\n",
      " [ -9.83422312]\n",
      " [-13.0385044 ]\n",
      " [-14.35106908]\n",
      " [-13.95158812]\n",
      " [-13.14228484]\n",
      " [-12.56217834]\n",
      " [-10.51257251]\n",
      " [-13.39820386]\n",
      " [-11.52532728]\n",
      " [-11.34281946]\n",
      " [-15.05594068]\n",
      " [-10.18492444]\n",
      " [-12.69968883]\n",
      " [-11.97999245]\n",
      " [-11.3527715 ]\n",
      " [ -8.11680606]\n",
      " [-13.4968062 ]\n",
      " [-10.99776187]\n",
      " [-13.65662778]\n",
      " [-11.50067923]\n",
      " [-14.20014746]\n",
      " [ -9.85424116]\n",
      " [-12.98434603]\n",
      " [-11.02299777]\n",
      " [-13.51195445]\n",
      " [-10.03624448]\n",
      " [-11.66678229]\n",
      " [-14.73031611]\n",
      " [-13.86890169]\n",
      " [-11.54555371]\n",
      " [-12.81445843]\n",
      " [-12.63818252]\n",
      " [-14.20401364]\n",
      " [-11.2275309 ]\n",
      " [-14.42506143]\n",
      " [ -9.0174488 ]\n",
      " [-12.86657281]\n",
      " [-13.41337584]\n",
      " [-10.62829117]\n",
      " [-13.88484505]\n",
      " [-13.08202489]\n",
      " [-13.00086357]\n",
      " [-10.14888963]\n",
      " [-12.04949152]\n",
      " [-12.1322401 ]\n",
      " [-13.30093398]\n",
      " [-14.91888627]\n",
      " [ -8.79504997]\n",
      " [ -8.72454255]\n",
      " [-11.94053966]\n",
      " [-13.42347591]\n",
      " [ -8.29501432]\n",
      " [-11.07105046]\n",
      " [-12.78860203]\n",
      " [-11.93453674]\n",
      " [ -9.57676466]\n",
      " [-13.86750864]\n",
      " [-12.31927807]\n",
      " [-14.83382258]\n",
      " [-11.35607108]\n",
      " [-12.04194495]\n",
      " [-13.67688563]\n",
      " [-10.86978527]\n",
      " [-11.56357268]\n",
      " [-12.6567203 ]\n",
      " [-13.1603071 ]\n",
      " [-14.22372749]\n",
      " [-10.15632342]\n",
      " [-13.40813435]\n",
      " [ -8.60544498]\n",
      " [-14.08021897]\n",
      " [-14.87802027]\n",
      " [ -9.90263381]\n",
      " [-12.68338931]\n",
      " [ -9.88462399]\n",
      " [-12.11130443]\n",
      " [-10.2730027 ]\n",
      " [-13.01015179]\n",
      " [-11.68713909]\n",
      " [ -8.67828509]\n",
      " [-13.87972024]\n",
      " [-12.61378521]\n",
      " [-11.46116919]\n",
      " [-10.10526282]\n",
      " [-13.01745793]\n",
      " [ -9.88414207]\n",
      " [-11.01332603]\n",
      " [-11.38201452]\n",
      " [-10.11548229]\n",
      " [-13.83318588]\n",
      " [ -8.00440012]\n",
      " [ -9.71425173]\n",
      " [-13.01942084]\n",
      " [-14.56057024]\n",
      " [-10.78642728]\n",
      " [-14.27313381]\n",
      " [-11.71639412]\n",
      " [ -9.42775393]\n",
      " [-14.01591316]\n",
      " [-12.39379135]\n",
      " [-11.96301404]\n",
      " [-13.21898007]\n",
      " [ -9.96840531]\n",
      " [-14.05683753]\n",
      " [-13.93453378]\n",
      " [-15.29466305]\n",
      " [-13.410579  ]\n",
      " [ -9.61822797]\n",
      " [-14.06268688]\n",
      " [ -9.46703358]\n",
      " [-14.45167094]\n",
      " [-14.75012864]\n",
      " [ -8.96149178]\n",
      " [-13.22990806]\n",
      " [-11.60264696]\n",
      " [-11.20899287]\n",
      " [-11.97141815]\n",
      " [ -9.82501426]\n",
      " [-13.03816155]\n",
      " [-12.84925402]\n",
      " [-10.24338357]\n",
      " [-11.43453372]\n",
      " [-15.010488  ]\n",
      " [-12.94129528]\n",
      " [-10.32481205]\n",
      " [ -9.21851437]\n",
      " [-10.45073427]\n",
      " [-12.52173132]\n",
      " [-13.04063749]\n",
      " [-12.93161268]\n",
      " [ -8.81711136]\n",
      " [ -7.4306068 ]\n",
      " [-14.04706262]\n",
      " [-12.50034209]\n",
      " [-13.56627009]\n",
      " [-11.95150803]\n",
      " [-10.35707636]\n",
      " [-15.33511649]\n",
      " [-11.19110899]\n",
      " [-14.33306626]\n",
      " [-14.46960254]\n",
      " [ -9.72187888]\n",
      " [-12.55378166]\n",
      " [-13.59295156]\n",
      " [-14.31905551]\n",
      " [-12.34952413]\n",
      " [ -8.95896056]\n",
      " [-12.12447887]\n",
      " [-11.13181283]\n",
      " [-14.35587913]\n",
      " [-14.349168  ]\n",
      " [ -9.96511194]\n",
      " [ -9.58657107]\n",
      " [-13.32541025]\n",
      " [-10.80039949]\n",
      " [-10.63043972]\n",
      " [-10.50668051]\n",
      " [-14.23328938]\n",
      " [-12.24756032]\n",
      " [-14.07284233]\n",
      " [ -9.79452341]\n",
      " [-13.35224886]\n",
      " [-12.93511079]\n",
      " [-13.64629517]\n",
      " [-12.89226049]\n",
      " [-10.69301835]\n",
      " [-10.58100872]\n",
      " [-13.15885774]\n",
      " [-13.62483795]\n",
      " [-12.07013038]\n",
      " [-14.02853177]\n",
      " [ -9.66370127]\n",
      " [-13.87189212]\n",
      " [-13.60510251]\n",
      " [ -9.92047371]\n",
      " [-14.27731356]\n",
      " [-12.45760932]\n",
      " [-13.88428032]\n",
      " [ -9.84722105]\n",
      " [-14.40189265]\n",
      " [-11.66969756]\n",
      " [-13.52106319]\n",
      " [-13.14102101]\n",
      " [-13.10674649]\n",
      " [-12.99757684]\n",
      " [-13.97204274]\n",
      " [-11.55131734]\n",
      " [-13.64636731]\n",
      " [-12.60035513]\n",
      " [-12.36959482]\n",
      " [-13.82872462]\n",
      " [-13.16907466]\n",
      " [-14.27025129]\n",
      " [-12.76371978]\n",
      " [-14.34436012]\n",
      " [-13.72943988]\n",
      " [-13.03877854]\n",
      " [-13.42059735]\n",
      " [-10.17200148]\n",
      " [-12.15440407]\n",
      " [-15.33813841]\n",
      " [-13.63208384]\n",
      " [-10.18981613]\n",
      " [-13.23389486]\n",
      " [-13.23636957]\n",
      " [ -9.34868425]\n",
      " [-13.90757919]\n",
      " [-10.38774513]\n",
      " [-11.76349566]\n",
      " [-10.87381356]\n",
      " [ -7.58332628]\n",
      " [-10.11244406]\n",
      " [ -8.79868859]\n",
      " [-13.86655193]\n",
      " [-12.28488417]\n",
      " [-11.53759834]\n",
      " [-14.25721262]\n",
      " [-12.32833959]\n",
      " [-14.10727749]\n",
      " [ -7.3389211 ]\n",
      " [-10.32449698]\n",
      " [-12.29797242]\n",
      " [ -9.80088331]\n",
      " [-10.96077074]\n",
      " [-12.31041966]\n",
      " [-14.29040684]\n",
      " [ -8.37824191]\n",
      " [-12.80999172]\n",
      " [ -9.69059361]\n",
      " [-10.50869171]\n",
      " [-12.5874568 ]\n",
      " [ -9.10091735]\n",
      " [-13.7195185 ]\n",
      " [-14.73397452]\n",
      " [-12.36132061]\n",
      " [-11.85001476]\n",
      " [-13.78154972]\n",
      " [-12.09301783]\n",
      " [-14.21543662]\n",
      " [-13.62995006]\n",
      " [ -9.15833139]\n",
      " [-13.44117281]\n",
      " [-13.49177713]\n",
      " [ -9.95905308]\n",
      " [-13.56848755]\n",
      " [ -9.7007009 ]\n",
      " [-11.23760502]\n",
      " [-10.06965909]\n",
      " [-12.69757179]\n",
      " [-13.60977664]\n",
      " [-13.33643798]\n",
      " [-12.01957696]\n",
      " [-10.05546677]\n",
      " [-10.78574703]\n",
      " [ -9.11909027]\n",
      " [-13.8901456 ]\n",
      " [-11.32391795]\n",
      " [-14.71294995]\n",
      " [-12.94137421]\n",
      " [ -7.38528032]\n",
      " [-13.93881402]\n",
      " [ -9.96289918]\n",
      " [-11.6233858 ]\n",
      " [-12.28113165]\n",
      " [-10.1377925 ]\n",
      " [-12.40831335]\n",
      " [-11.71912387]\n",
      " [-14.04849533]\n",
      " [-12.01462671]\n",
      " [-13.66338164]\n",
      " [-13.18452218]\n",
      " [-13.60049335]\n",
      " [-10.69503787]\n",
      " [-12.3456655 ]\n",
      " [-13.6035175 ]\n",
      " [ -9.86541497]\n",
      " [-13.62637226]\n",
      " [ -9.74809691]\n",
      " [-11.36758296]\n",
      " [-14.17346312]\n",
      " [-14.19218753]\n",
      " [ -9.60008656]\n",
      " [ -8.29735745]\n",
      " [-10.31544892]\n",
      " [-10.792997  ]\n",
      " [-13.16030735]\n",
      " [-13.25429518]\n",
      " [-14.92662864]\n",
      " [-13.67388431]\n",
      " [-14.54810911]\n",
      " [-14.27107326]\n",
      " [-13.15038124]\n",
      " [-10.19330194]\n",
      " [-13.34562606]\n",
      " [-11.02167208]\n",
      " [-13.8363438 ]\n",
      " [-14.20715452]\n",
      " [-13.94416913]\n",
      " [ -7.97391995]\n",
      " [-13.78002572]\n",
      " [-14.03785135]\n",
      " [-12.53266659]\n",
      " [-14.55593091]\n",
      " [ -8.68126644]\n",
      " [-12.58804305]\n",
      " [-13.50695168]\n",
      " [-14.30938026]\n",
      " [-14.14225345]\n",
      " [-10.4610687 ]\n",
      " [ -8.99665084]\n",
      " [ -3.49424683]\n",
      " [ -6.80002195]\n",
      " [ -6.88478919]\n",
      " [ -4.84066242]\n",
      " [ -6.46387126]\n",
      " [ -8.17845701]\n",
      " [ -3.79045832]\n",
      " [ -6.4701097 ]\n",
      " [ -8.05413044]\n",
      " [ -5.43591167]\n",
      " [ -4.60269847]\n",
      " [ -9.82051417]\n",
      " [ -3.83754325]\n",
      " [ -9.93608801]\n",
      " [ -5.8644393 ]\n",
      " [-10.67417673]\n",
      " [ -7.30257372]\n",
      " [ -5.98869266]\n",
      " [ -3.11267733]\n",
      " [ -8.75619971]\n",
      " [ -8.6509926 ]\n",
      " [ -9.78606184]\n",
      " [ -8.14972461]\n",
      " [ -4.38725358]\n",
      " [ -7.65868196]\n",
      " [ -3.71208718]\n",
      " [ -5.40153309]\n",
      " [ -2.83112912]\n",
      " [ -5.50045548]\n",
      " [ -4.16301714]\n",
      " [ -4.39582888]\n",
      " [ -4.00716016]\n",
      " [ -5.89269011]\n",
      " [ -9.20235549]\n",
      " [ -4.19827957]\n",
      " [ -4.71711964]\n",
      " [ -3.43480253]\n",
      " [ -4.44632874]\n",
      " [ -4.68894865]\n",
      " [ -9.4539647 ]\n",
      " [ -3.61813847]\n",
      " [ -3.18048654]\n",
      " [ -4.84172608]\n",
      " [ -3.51561169]\n",
      " [ -6.98615701]\n",
      " [ -3.55492238]\n",
      " [ -5.94904268]\n",
      " [ -3.39592701]\n",
      " [ -7.75007039]\n",
      " [ -9.65673572]\n",
      " [ -3.36320247]\n",
      " [ -6.83402497]\n",
      " [ -4.76214269]\n",
      " [ -3.32982557]\n",
      " [ -6.51265484]\n",
      " [ -4.33379797]\n",
      " [ -8.36132349]\n",
      " [ -3.66227221]\n",
      " [ -4.97444137]\n",
      " [ -3.85328751]\n",
      " [ -4.18390142]\n",
      " [ -9.78365737]\n",
      " [ -7.48476482]\n",
      " [ -5.5649755 ]\n",
      " [ -4.79548536]\n",
      " [ -9.15519294]\n",
      " [ -5.92571089]\n",
      " [ -6.75871972]\n",
      " [ -5.80545843]\n",
      " [ -7.08057777]\n",
      " [ -4.41014549]\n",
      " [ -4.3721229 ]\n",
      " [ -4.45019238]\n",
      " [ -3.35751061]\n",
      " [ -4.41135657]\n",
      " [ -7.4744979 ]\n",
      " [ -9.45084411]\n",
      " [ -4.9018824 ]\n",
      " [ -4.0466844 ]\n",
      " [ -6.36926338]\n",
      " [ -4.00344519]\n",
      " [ -7.51659237]\n",
      " [ -5.13644706]\n",
      " [ -4.89591812]\n",
      " [ -6.09067657]\n",
      " [ -4.76979951]\n",
      " [ -4.59563887]\n",
      " [ -6.07518413]\n",
      " [ -6.75031391]\n",
      " [ -4.35442156]\n",
      " [ -5.24094454]\n",
      " [ -8.47408576]\n",
      " [ -6.67682599]\n",
      " [ -3.84061346]\n",
      " [ -7.10073166]\n",
      " [ -8.76585476]\n",
      " [ -8.87641443]\n",
      " [ -8.94684606]\n",
      " [ -2.95366209]\n",
      " [ -8.1592656 ]\n",
      " [ -5.57577984]\n",
      " [ -3.38137707]\n",
      " [ -8.21928555]\n",
      " [ -8.73501988]\n",
      " [ -7.98088669]\n",
      " [ -6.23134502]\n",
      " [ -5.53024055]\n",
      " [ -4.46122777]\n",
      " [ -5.24953772]\n",
      " [ -3.71379883]\n",
      " [ -7.77500547]\n",
      " [ -4.11494584]\n",
      " [ -7.73964562]\n",
      " [-10.32127177]\n",
      " [ -4.17420576]\n",
      " [ -3.9872091 ]\n",
      " [ -9.25454892]\n",
      " [ -4.04984542]\n",
      " [ -7.84390171]\n",
      " [ -5.77533577]\n",
      " [ -4.80324357]\n",
      " [ -9.82556807]\n",
      " [ -5.80022285]\n",
      " [ -4.50355309]\n",
      " [ -5.9463878 ]\n",
      " [ -6.70625974]\n",
      " [ -7.67424079]\n",
      " [ -6.74994549]\n",
      " [ -4.29940285]\n",
      " [ -8.18446372]\n",
      " [ -6.57183507]\n",
      " [ -6.7507999 ]\n",
      " [ -7.76076413]\n",
      " [ -6.87905764]\n",
      " [ -4.54276685]\n",
      " [ -6.01900922]\n",
      " [ -4.02122651]\n",
      " [ -4.08398743]\n",
      " [ -4.66063845]\n",
      " [ -5.70282501]\n",
      " [ -5.23543986]\n",
      " [ -9.55945996]\n",
      " [ -4.68062602]\n",
      " [ -3.26730068]\n",
      " [ -2.98370206]\n",
      " [ -3.59220481]\n",
      " [ -9.72804237]\n",
      " [ -5.76630656]\n",
      " [ -6.70877473]\n",
      " [ -9.44893737]\n",
      " [ -5.9561198 ]\n",
      " [ -5.55011412]\n",
      " [ -7.53910529]\n",
      " [ -8.86817119]\n",
      " [ -5.69270758]\n",
      " [ -4.019241  ]\n",
      " [ -4.59304375]\n",
      " [ -5.27782588]\n",
      " [ -5.50660333]\n",
      " [-10.62246106]\n",
      " [-10.584831  ]\n",
      " [ -5.1764226 ]\n",
      " [ -4.00182163]\n",
      " [ -3.3783488 ]\n",
      " [ -4.26911192]\n",
      " [ -7.51094993]\n",
      " [ -9.81071005]\n",
      " [ -4.01477174]\n",
      " [ -8.33873588]\n",
      " [ -6.26718774]\n",
      " [ -4.65896836]\n",
      " [ -3.62314739]\n",
      " [ -8.3443536 ]\n",
      " [ -7.55457774]\n",
      " [ -4.25054295]\n",
      " [ -3.50226939]\n",
      " [ -5.70714434]\n",
      " [ -3.86872172]\n",
      " [ -5.79810818]\n",
      " [ -4.40674245]\n",
      " [ -6.27863623]\n",
      " [ -3.8468816 ]\n",
      " [ -4.71420639]\n",
      " [ -4.18388544]\n",
      " [ -5.93998177]\n",
      " [ -4.71728147]\n",
      " [ -4.15210804]\n",
      " [ -7.41885134]\n",
      " [ -4.80297797]\n",
      " [ -8.28875513]\n",
      " [ -9.11650732]\n",
      " [ -7.67080118]\n",
      " [ -4.34703129]\n",
      " [ -4.51226229]\n",
      " [ -3.72023991]\n",
      " [ -4.40325976]\n",
      " [ -4.93191294]\n",
      " [ -6.33587916]\n",
      " [ -4.06467423]\n",
      " [ -7.2013846 ]\n",
      " [ -9.91482879]\n",
      " [ -4.45933524]\n",
      " [ -5.51894719]\n",
      " [ -4.02133589]\n",
      " [ -3.64880564]\n",
      " [ -4.72369336]\n",
      " [ -6.87495282]\n",
      " [ -6.71017238]\n",
      " [ -5.63773818]\n",
      " [ -4.89718202]\n",
      " [ -7.96647692]\n",
      " [ -8.35069835]\n",
      " [ -5.415081  ]\n",
      " [ -7.28511508]\n",
      " [ -4.65867938]\n",
      " [ -4.52665874]\n",
      " [ -3.93675457]\n",
      " [ -7.90486187]\n",
      " [ -4.16316122]\n",
      " [ -3.57524527]\n",
      " [ -4.88171413]\n",
      " [ -3.45511504]\n",
      " [ -3.74377903]\n",
      " [ -7.0625918 ]\n",
      " [ -4.12500968]\n",
      " [ -9.86111346]\n",
      " [ -5.80902742]\n",
      " [ -7.9746392 ]\n",
      " [ -5.85754811]\n",
      " [ -5.7852016 ]\n",
      " [ -4.98196686]\n",
      " [ -3.62178391]\n",
      " [ -5.06930779]\n",
      " [ -4.10712749]\n",
      " [ -4.63290833]\n",
      " [ -5.48305414]\n",
      " [ -3.68586766]\n",
      " [ -2.69236048]\n",
      " [ -4.77685006]\n",
      " [ -2.96121739]\n",
      " [ -9.62227159]\n",
      " [ -4.88504488]\n",
      " [ -6.45213701]\n",
      " [ -4.03174771]\n",
      " [ -4.95501246]\n",
      " [ -3.50298944]\n",
      " [ -4.81278164]\n",
      " [ -4.29506684]\n",
      " [ -4.62859277]\n",
      " [ -3.56000063]\n",
      " [ -8.98319347]\n",
      " [ -9.61055461]\n",
      " [ -4.82250912]\n",
      " [ -4.2314367 ]\n",
      " [ -6.94563464]\n",
      " [ -5.14752933]\n",
      " [ -9.22598696]\n",
      " [ -7.7498621 ]\n",
      " [ -5.3074537 ]\n",
      " [ -6.86166866]\n",
      " [ -8.01162234]\n",
      " [ -3.544417  ]\n",
      " [ -9.51802783]\n",
      " [ -6.47002648]\n",
      " [ -5.73861908]\n",
      " [ -4.56716881]\n",
      " [ -4.78508738]\n",
      " [ -6.40962017]\n",
      " [ -3.7304767 ]\n",
      " [ -9.05238137]\n",
      " [ -4.57904456]\n",
      " [ -5.81413636]\n",
      " [ -9.06346336]\n",
      " [ -6.84005664]\n",
      " [ -4.73247231]\n",
      " [ -4.12259445]\n",
      " [ -4.43177523]\n",
      " [ -5.24329452]\n",
      " [ -6.49629165]\n",
      " [ -6.60220034]\n",
      " [ -5.73924643]\n",
      " [ -3.92519183]\n",
      " [ -8.74113689]\n",
      " [ -3.82713339]\n",
      " [ -5.15641356]\n",
      " [ -4.35814779]\n",
      " [ -5.02467723]\n",
      " [ -9.50412434]\n",
      " [ -6.57408302]\n",
      " [ -7.85965551]\n",
      " [ -4.59548463]\n",
      " [ -7.49755707]\n",
      " [ -5.16193322]\n",
      " [ -9.47258201]\n",
      " [ -6.13641421]\n",
      " [ -4.33301806]\n",
      " [ -3.74869836]\n",
      " [ -4.68382313]\n",
      " [ -6.15137808]\n",
      " [ -3.29470357]\n",
      " [ -4.03089691]\n",
      " [ -5.24400994]\n",
      " [ -8.87024083]\n",
      " [ -3.61389554]\n",
      " [ -8.48854218]\n",
      " [ -6.87565443]\n",
      " [-10.66807727]\n",
      " [ -3.94977839]\n",
      " [-10.32087627]\n",
      " [ -8.35085802]\n",
      " [ -5.5553601 ]\n",
      " [ -5.73812524]\n",
      " [ -4.37070322]\n",
      " [ -6.24541229]\n",
      " [ -4.51240184]\n",
      " [ -3.91888464]\n",
      " [ -5.65568684]\n",
      " [ -2.7729345 ]\n",
      " [ -8.87286082]\n",
      " [ -6.84296277]\n",
      " [ -6.33126639]\n",
      " [ -9.14124592]\n",
      " [ -8.03579464]\n",
      " [ -9.67946095]\n",
      " [ -2.78823549]\n",
      " [ -6.99395775]\n",
      " [ -9.91964564]\n",
      " [ -8.52281311]\n",
      " [ -5.8796005 ]\n",
      " [ -6.21501347]\n",
      " [ -5.34795855]\n",
      " [ -7.96925176]\n",
      " [ -3.71979156]\n",
      " [ -5.2954525 ]\n",
      " [ -4.89820791]\n",
      " [ -4.61691839]\n",
      " [ -4.13951047]\n",
      " [ -8.07191154]\n",
      " [ -8.00742635]\n",
      " [ -8.80792539]\n",
      " [ -4.41869359]\n",
      " [ -9.65959613]\n",
      " [ -7.11554398]\n",
      " [ -4.99651504]\n",
      " [ -5.68454944]\n",
      " [ -9.14022033]\n",
      " [ -3.61462504]\n",
      " [ -4.08871104]\n",
      " [ -4.77845114]\n",
      " [ -4.7831646 ]\n",
      " [ -7.38118955]\n",
      " [ -4.49290944]\n",
      " [ -3.56453947]\n",
      " [ -5.97157878]\n",
      " [ -4.19792127]\n",
      " [ -4.41173222]\n",
      " [ -8.56877618]\n",
      " [ -5.96711557]\n",
      " [ -4.44386561]\n",
      " [-10.07300331]\n",
      " [ -4.95575441]\n",
      " [-10.63203368]\n",
      " [ -4.03387964]\n",
      " [ -4.92614239]\n",
      " [ -4.24168363]\n",
      " [ -3.3839511 ]\n",
      " [ -9.22358336]\n",
      " [ -8.64776145]\n",
      " [ -6.08014236]\n",
      " [ -5.38609084]\n",
      " [ -6.68481981]\n",
      " [ -5.15985906]\n",
      " [ -3.46934739]\n",
      " [ -4.89686132]\n",
      " [ -7.30867392]\n",
      " [ -7.99148715]\n",
      " [ -8.63829104]\n",
      " [ -6.69758974]\n",
      " [ -4.90067331]\n",
      " [ -4.42628101]\n",
      " [ -5.68493491]\n",
      " [ -4.93346846]\n",
      " [ -3.00397114]\n",
      " [ -6.29863198]\n",
      " [ -8.67664169]\n",
      " [ -3.47602014]\n",
      " [ -3.72654484]\n",
      " [ -4.54187048]\n",
      " [ -2.99164223]\n",
      " [ -5.51032331]\n",
      " [ -8.52415881]\n",
      " [ -5.20953761]\n",
      " [ -7.35384792]\n",
      " [ -8.10121454]\n",
      " [ -9.83377758]\n",
      " [ -9.05869974]\n",
      " [ -8.15716898]\n",
      " [ -5.41354494]\n",
      " [ -4.47548384]\n",
      " [ -7.97146024]\n",
      " [ -6.74875958]\n",
      " [ -3.65424251]\n",
      " [ -8.52763073]\n",
      " [ -6.88314494]\n",
      " [ -4.52892938]\n",
      " [ -4.78807197]\n",
      " [ -4.71543748]\n",
      " [ -2.99442496]\n",
      " [ -5.22643007]\n",
      " [ -8.94863173]\n",
      " [ -7.23093783]\n",
      " [ -4.05338844]\n",
      " [ -4.78945372]\n",
      " [ -4.67345567]\n",
      " [ -5.76260814]\n",
      " [ -6.24536283]\n",
      " [ -4.52297583]\n",
      " [ -7.30756528]\n",
      " [ -6.26376848]\n",
      " [ -9.65923083]\n",
      " [ -5.77722349]\n",
      " [ -7.79372968]\n",
      " [ -4.23893524]\n",
      " [ -9.39990652]\n",
      " [ -8.20553921]\n",
      " [ -7.06353713]\n",
      " [ -9.25895217]\n",
      " [ -8.61008388]\n",
      " [ -6.09470012]\n",
      " [ -5.26374768]\n",
      " [ -3.29742509]\n",
      " [ -4.28633665]\n",
      " [-10.43118707]\n",
      " [ -7.2885753 ]\n",
      " [ -4.54568378]\n",
      " [ -4.81788407]\n",
      " [ -4.79586076]\n",
      " [ -6.73639729]\n",
      " [ -8.24894271]\n",
      " [ -8.43564656]\n",
      " [ -9.12358352]\n",
      " [ -5.6488505 ]\n",
      " [ -5.35738211]\n",
      " [ -5.14288427]\n",
      " [ -9.7062011 ]\n",
      " [ -7.08895634]\n",
      " [ -3.59440578]\n",
      " [ -3.82833464]\n",
      " [ -6.87678831]\n",
      " [ -9.7351744 ]\n",
      " [ -3.77943714]\n",
      " [ -7.10405909]\n",
      " [ -4.25054293]\n",
      " [ -5.98912965]\n",
      " [ -5.29398549]\n",
      " [ -5.94311405]\n",
      " [ -5.5114088 ]\n",
      " [ -4.52622371]\n",
      " [ -4.61819608]\n",
      " [ -6.27945424]\n",
      " [ -3.81889184]\n",
      " [ -5.06792636]\n",
      " [ -4.28016976]\n",
      " [ -3.02592194]\n",
      " [ -6.48765128]\n",
      " [ -7.22548159]\n",
      " [ -6.85768336]\n",
      " [ -6.695779  ]\n",
      " [ -7.91976634]\n",
      " [ -8.11090479]\n",
      " [ -9.92410305]\n",
      " [ -7.0689871 ]\n",
      " [ -8.58018739]\n",
      " [ -3.66636629]\n",
      " [ -9.12566364]\n",
      " [ -8.67240932]\n",
      " [ -5.22489326]\n",
      " [ -4.52780055]\n",
      " [ -4.16875273]\n",
      " [ -4.29706578]\n",
      " [ -3.74170795]\n",
      " [ -8.54393713]\n",
      " [ -6.33151141]\n",
      " [ -6.33061136]\n",
      " [ -7.24433591]\n",
      " [ -6.53317048]\n",
      " [ -3.59305453]\n",
      " [ -5.2067951 ]\n",
      " [ -5.3984372 ]\n",
      " [ -7.80988888]\n",
      " [ -3.86206566]\n",
      " [ -5.86750358]\n",
      " [ -6.22554229]\n",
      " [ -6.2427313 ]\n",
      " [ -5.16290993]\n",
      " [ -5.1784986 ]\n",
      " [ -7.70216847]\n",
      " [ -5.5051072 ]\n",
      " [ -4.10712701]]\n"
     ]
    }
   ],
   "source": [
    "# io dev\n",
    "X_dev = []\n",
    "Y_dev = []\n",
    "with open(\"synthetic_dataset/dev.txt\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        X_dev.append([float(row[0]), float(row[1])])\n",
    "        Y_dev.append([int(row[2])-1])\n",
    "        \n",
    "# X_dev = PredictorScaler.transform(X_dev)\n",
    "X_dev = np.array(X_dev, dtype=np.float64)\n",
    "Y_dev = np.array(Y_dev, dtype=np.float64)\n",
    "\n",
    "ldamachine = FDA(X_dev,[x for [x] in Y_dev],1)\n",
    "X_dev = ldamachine.get_transformed_data()\n",
    "print(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instance of one-hot-encoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# create df_Y\n",
    "df_Y = pd.DataFrame(np.array(Y,dtype=int))\n",
    "\n",
    "#perform one-hot encoding on  Y\n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(Y.reshape(-1,1)).toarray())\n",
    "Yhat = encoder_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(T.nn.Module):\n",
    "    def __init__(self, dataset_type=None, args=None):\n",
    "        super(ANN, self).__init__()\n",
    "        if(dataset_type == None):\n",
    "            print(\"Dataset type not mentioned. Assuming Synthetic dataset.\")\n",
    "            dataset_type = 'syn'\n",
    "        self.dataset_type = dataset_type\n",
    "        if(dataset_type == 'image'):\n",
    "            self.classifier = Sequential()\n",
    "            self.classifier.add(Dense(46,input_dim=23,activation='tanh'))\n",
    "            self.classifier.add(Dense(5,activation='sigmoid'))\n",
    "            self.classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            pass\n",
    "        if(dataset_type == 'syn'):\n",
    "            if(args==None):\n",
    "                hid1 = 4\n",
    "                hid2 = 6\n",
    "            else:\n",
    "                hid1,hid2 = args\n",
    "            self.hid1 = T.nn.Linear(1, hid1)  # 2-(3-4)-1\n",
    "            self.hid2 = T.nn.Linear(hid1, hid2)\n",
    "            self.oupt = T.nn.Linear(hid2, 1)\n",
    "\n",
    "            T.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "            T.nn.init.zeros_(self.hid1.bias)\n",
    "            T.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "            T.nn.init.zeros_(self.hid2.bias)\n",
    "            T.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "            T.nn.init.zeros_(self.oupt.bias)\n",
    "            pass\n",
    "        if(dataset_type == 'isodigit'):\n",
    "            pass\n",
    "        if(dataset_type == 'handwritten'):\n",
    "            pass\n",
    "        self.history = None\n",
    "        \n",
    "    # def __call__(self,X,Y,n_epochs=100,bat_size=10):\n",
    "    #     self.history = self.classifier.fit(X,Y,batch_size=bat_size,epochs=n_epochs,verbose=1) \n",
    "    #     return self.history\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if(self.dataset_type == 'syn'):\n",
    "            z = T.tanh(self.hid1(x)) \n",
    "            z = T.tanh(self.hid2(z))\n",
    "            z = T.sigmoid(self.oupt(z))\n",
    "            return z\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ANN(dataset_type='syn', args=[10,5]).to('cuda')\n",
    "net = net.train()  # set training mode\n",
    "lrn_rate = 1e-4\n",
    "bat_size = 125\n",
    "loss_func = T.nn.BCELoss().cuda()  # softmax() + binary CE\n",
    "optimizer = T.optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "max_epochs = 40000\n",
    "n_items = len(X)\n",
    "batcher = Batcher(n_items, bat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d78e0e29d04fa390665992dc8648df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =     10  batch loss = 14.1303 train accuracy = 51.56 dev accuracy = 51.90\n",
      "epoch =     20  batch loss = 12.4303 train accuracy = 75.24 dev accuracy = 75.30\n",
      "epoch =     30  batch loss = 11.6092 train accuracy = 85.96 dev accuracy = 86.30\n",
      "epoch =     40  batch loss = 11.0288 train accuracy = 89.04 dev accuracy = 89.00\n",
      "epoch =     50  batch loss = 10.4196 train accuracy = 89.84 dev accuracy = 90.10\n",
      "epoch =     60  batch loss =  9.8003 train accuracy = 90.32 dev accuracy = 90.20\n",
      "epoch =     70  batch loss =  9.2227 train accuracy = 90.20 dev accuracy = 90.20\n",
      "epoch =     80  batch loss =  8.6825 train accuracy = 90.40 dev accuracy = 90.20\n",
      "epoch =     90  batch loss =  8.1494 train accuracy = 90.36 dev accuracy = 90.30\n",
      "epoch =    100  batch loss =  7.6151 train accuracy = 90.36 dev accuracy = 90.30\n",
      "epoch =    110  batch loss =  7.1030 train accuracy = 90.32 dev accuracy = 90.20\n",
      "epoch =    120  batch loss =  6.6464 train accuracy = 90.36 dev accuracy = 90.20\n",
      "epoch =    130  batch loss =  6.2638 train accuracy = 90.20 dev accuracy = 90.80\n",
      "epoch =    140  batch loss =  5.9510 train accuracy = 90.16 dev accuracy = 90.80\n",
      "epoch =    150  batch loss =  5.6897 train accuracy = 90.16 dev accuracy = 90.90\n",
      "epoch =    160  batch loss =  5.4671 train accuracy = 90.28 dev accuracy = 90.70\n",
      "epoch =    170  batch loss =  5.2739 train accuracy = 90.32 dev accuracy = 90.70\n",
      "epoch =    180  batch loss =  5.1050 train accuracy = 90.32 dev accuracy = 91.00\n",
      "epoch =    190  batch loss =  4.9578 train accuracy = 90.48 dev accuracy = 90.80\n",
      "epoch =    200  batch loss =  4.8296 train accuracy = 90.48 dev accuracy = 90.80\n",
      "epoch =    210  batch loss =  4.7174 train accuracy = 90.32 dev accuracy = 91.00\n",
      "epoch =    220  batch loss =  4.6189 train accuracy = 90.16 dev accuracy = 91.00\n",
      "epoch =    230  batch loss =  4.5330 train accuracy = 90.16 dev accuracy = 90.80\n",
      "epoch =    240  batch loss =  4.4583 train accuracy = 90.08 dev accuracy = 90.80\n",
      "epoch =    250  batch loss =  4.3933 train accuracy = 90.16 dev accuracy = 90.80\n",
      "epoch =    260  batch loss =  4.3367 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =    270  batch loss =  4.2875 train accuracy = 90.08 dev accuracy = 90.80\n",
      "epoch =    280  batch loss =  4.2447 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =    290  batch loss =  4.2086 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    300  batch loss =  4.1779 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    310  batch loss =  4.1490 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    320  batch loss =  4.1256 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    330  batch loss =  4.1057 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    340  batch loss =  4.0881 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    350  batch loss =  4.0731 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    360  batch loss =  4.0611 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    370  batch loss =  4.0499 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =    380  batch loss =  4.0412 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =    390  batch loss =  4.0329 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    400  batch loss =  4.0273 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =    410  batch loss =  4.0219 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    420  batch loss =  4.0167 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    430  batch loss =  4.0128 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =    440  batch loss =  4.0099 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    450  batch loss =  4.0064 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    460  batch loss =  4.0041 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    470  batch loss =  4.0026 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    480  batch loss =  4.0007 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    490  batch loss =  3.9989 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    500  batch loss =  3.9979 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    510  batch loss =  3.9964 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    520  batch loss =  3.9952 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =    530  batch loss =  3.9950 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    540  batch loss =  3.9942 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    550  batch loss =  3.9936 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =    560  batch loss =  3.9933 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    570  batch loss =  3.9922 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    580  batch loss =  3.9923 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =    590  batch loss =  3.9916 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =    600  batch loss =  3.9905 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    610  batch loss =  3.9911 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =    620  batch loss =  3.9897 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    630  batch loss =  3.9909 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    640  batch loss =  3.9891 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =    650  batch loss =  3.9893 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    660  batch loss =  3.9898 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    670  batch loss =  3.9885 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    680  batch loss =  3.9871 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =    690  batch loss =  3.9877 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    700  batch loss =  3.9869 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    710  batch loss =  3.9865 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =    720  batch loss =  3.9865 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    730  batch loss =  3.9852 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    740  batch loss =  3.9863 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    750  batch loss =  3.9855 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =    760  batch loss =  3.9846 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =    770  batch loss =  3.9845 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    780  batch loss =  3.9842 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    790  batch loss =  3.9842 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    800  batch loss =  3.9832 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =    810  batch loss =  3.9832 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    820  batch loss =  3.9821 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =    830  batch loss =  3.9826 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    840  batch loss =  3.9814 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    850  batch loss =  3.9807 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    860  batch loss =  3.9809 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    870  batch loss =  3.9806 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    880  batch loss =  3.9799 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    890  batch loss =  3.9795 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =    900  batch loss =  3.9816 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =    910  batch loss =  3.9786 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    920  batch loss =  3.9781 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =    930  batch loss =  3.9785 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =    940  batch loss =  3.9781 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =    950  batch loss =  3.9778 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =    960  batch loss =  3.9777 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =    970  batch loss =  3.9757 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =    980  batch loss =  3.9765 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =    990  batch loss =  3.9766 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1000  batch loss =  3.9760 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1010  batch loss =  3.9759 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1020  batch loss =  3.9752 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1030  batch loss =  3.9744 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   1040  batch loss =  3.9736 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1050  batch loss =  3.9735 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   1060  batch loss =  3.9725 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1070  batch loss =  3.9729 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1080  batch loss =  3.9717 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1090  batch loss =  3.9724 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1100  batch loss =  3.9726 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1110  batch loss =  3.9703 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1120  batch loss =  3.9709 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1130  batch loss =  3.9704 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   1140  batch loss =  3.9705 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1150  batch loss =  3.9695 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1160  batch loss =  3.9712 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   1170  batch loss =  3.9692 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1180  batch loss =  3.9681 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   1190  batch loss =  3.9677 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1200  batch loss =  3.9677 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1210  batch loss =  3.9664 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   1220  batch loss =  3.9654 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   1230  batch loss =  3.9668 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1240  batch loss =  3.9660 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1250  batch loss =  3.9652 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1260  batch loss =  3.9647 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1270  batch loss =  3.9634 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1280  batch loss =  3.9634 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1290  batch loss =  3.9627 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1300  batch loss =  3.9627 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1310  batch loss =  3.9627 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1320  batch loss =  3.9615 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1330  batch loss =  3.9610 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   1340  batch loss =  3.9608 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1350  batch loss =  3.9605 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1360  batch loss =  3.9604 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1370  batch loss =  3.9595 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   1380  batch loss =  3.9601 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   1390  batch loss =  3.9583 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1400  batch loss =  3.9578 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1410  batch loss =  3.9570 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1420  batch loss =  3.9571 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1430  batch loss =  3.9566 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1440  batch loss =  3.9567 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1450  batch loss =  3.9559 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1460  batch loss =  3.9550 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1470  batch loss =  3.9550 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   1480  batch loss =  3.9549 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1490  batch loss =  3.9540 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1500  batch loss =  3.9533 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1510  batch loss =  3.9525 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1520  batch loss =  3.9531 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1530  batch loss =  3.9527 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1540  batch loss =  3.9513 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1550  batch loss =  3.9519 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1560  batch loss =  3.9506 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   1570  batch loss =  3.9514 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1580  batch loss =  3.9500 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1590  batch loss =  3.9491 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1600  batch loss =  3.9495 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1610  batch loss =  3.9509 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1620  batch loss =  3.9483 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1630  batch loss =  3.9480 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   1640  batch loss =  3.9475 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   1650  batch loss =  3.9463 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1660  batch loss =  3.9468 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1670  batch loss =  3.9454 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1680  batch loss =  3.9451 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1690  batch loss =  3.9451 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1700  batch loss =  3.9449 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1710  batch loss =  3.9447 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1720  batch loss =  3.9435 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   1730  batch loss =  3.9436 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1740  batch loss =  3.9440 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1750  batch loss =  3.9422 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   1760  batch loss =  3.9421 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1770  batch loss =  3.9421 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1780  batch loss =  3.9410 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1790  batch loss =  3.9417 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1800  batch loss =  3.9414 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1810  batch loss =  3.9398 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1820  batch loss =  3.9397 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1830  batch loss =  3.9400 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1840  batch loss =  3.9391 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1850  batch loss =  3.9388 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   1860  batch loss =  3.9390 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   1870  batch loss =  3.9381 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   1880  batch loss =  3.9370 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1890  batch loss =  3.9362 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   1900  batch loss =  3.9369 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1910  batch loss =  3.9363 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1920  batch loss =  3.9356 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1930  batch loss =  3.9357 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   1940  batch loss =  3.9349 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1950  batch loss =  3.9347 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1960  batch loss =  3.9347 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   1970  batch loss =  3.9336 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   1980  batch loss =  3.9338 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   1990  batch loss =  3.9345 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   2000  batch loss =  3.9330 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2010  batch loss =  3.9318 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2020  batch loss =  3.9315 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   2030  batch loss =  3.9321 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2040  batch loss =  3.9312 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2050  batch loss =  3.9313 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   2060  batch loss =  3.9306 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2070  batch loss =  3.9295 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2080  batch loss =  3.9295 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2090  batch loss =  3.9297 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2100  batch loss =  3.9294 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   2110  batch loss =  3.9292 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2120  batch loss =  3.9278 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2130  batch loss =  3.9292 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   2140  batch loss =  3.9291 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   2150  batch loss =  3.9267 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   2160  batch loss =  3.9267 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2170  batch loss =  3.9270 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2180  batch loss =  3.9274 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   2190  batch loss =  3.9262 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2200  batch loss =  3.9257 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2210  batch loss =  3.9249 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2220  batch loss =  3.9250 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   2230  batch loss =  3.9244 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2240  batch loss =  3.9236 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2250  batch loss =  3.9236 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2260  batch loss =  3.9232 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2270  batch loss =  3.9232 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   2280  batch loss =  3.9222 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2290  batch loss =  3.9222 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2300  batch loss =  3.9221 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2310  batch loss =  3.9209 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2320  batch loss =  3.9211 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2330  batch loss =  3.9216 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2340  batch loss =  3.9206 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   2350  batch loss =  3.9199 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2360  batch loss =  3.9199 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   2370  batch loss =  3.9191 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2380  batch loss =  3.9188 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2390  batch loss =  3.9188 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2400  batch loss =  3.9176 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2410  batch loss =  3.9183 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2420  batch loss =  3.9177 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   2430  batch loss =  3.9178 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2440  batch loss =  3.9175 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2450  batch loss =  3.9169 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2460  batch loss =  3.9165 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2470  batch loss =  3.9169 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2480  batch loss =  3.9158 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2490  batch loss =  3.9144 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   2500  batch loss =  3.9150 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   2510  batch loss =  3.9160 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2520  batch loss =  3.9152 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2530  batch loss =  3.9136 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2540  batch loss =  3.9131 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2550  batch loss =  3.9133 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2560  batch loss =  3.9128 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2570  batch loss =  3.9124 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   2580  batch loss =  3.9121 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2590  batch loss =  3.9118 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2600  batch loss =  3.9110 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2610  batch loss =  3.9107 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   2620  batch loss =  3.9106 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2630  batch loss =  3.9104 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   2640  batch loss =  3.9108 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2650  batch loss =  3.9101 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2660  batch loss =  3.9105 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2670  batch loss =  3.9091 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2680  batch loss =  3.9091 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2690  batch loss =  3.9080 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2700  batch loss =  3.9077 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2710  batch loss =  3.9076 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2720  batch loss =  3.9073 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2730  batch loss =  3.9069 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2740  batch loss =  3.9072 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   2750  batch loss =  3.9064 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2760  batch loss =  3.9076 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2770  batch loss =  3.9077 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2780  batch loss =  3.9057 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2790  batch loss =  3.9042 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2800  batch loss =  3.9047 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2810  batch loss =  3.9037 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2820  batch loss =  3.9054 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2830  batch loss =  3.9049 train accuracy = 89.64 dev accuracy = 91.20\n",
      "epoch =   2840  batch loss =  3.9029 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2850  batch loss =  3.9033 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2860  batch loss =  3.9033 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2870  batch loss =  3.9026 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2880  batch loss =  3.9023 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   2890  batch loss =  3.9007 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2900  batch loss =  3.9011 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2910  batch loss =  3.9002 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2920  batch loss =  3.9013 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   2930  batch loss =  3.9007 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   2940  batch loss =  3.8994 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   2950  batch loss =  3.8988 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   2960  batch loss =  3.8987 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   2970  batch loss =  3.9009 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   2980  batch loss =  3.8985 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   2990  batch loss =  3.8991 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   3000  batch loss =  3.8974 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3010  batch loss =  3.8973 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3020  batch loss =  3.8976 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   3030  batch loss =  3.8957 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   3040  batch loss =  3.8964 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3050  batch loss =  3.8958 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3060  batch loss =  3.8968 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3070  batch loss =  3.8946 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3080  batch loss =  3.8946 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3090  batch loss =  3.8934 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3100  batch loss =  3.8934 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   3110  batch loss =  3.8940 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3120  batch loss =  3.8934 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3130  batch loss =  3.8923 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   3140  batch loss =  3.8927 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3150  batch loss =  3.8919 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3160  batch loss =  3.8909 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3170  batch loss =  3.8907 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3180  batch loss =  3.8904 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3190  batch loss =  3.8909 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3200  batch loss =  3.8905 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3210  batch loss =  3.8900 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3220  batch loss =  3.8887 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3230  batch loss =  3.8892 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   3240  batch loss =  3.8885 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3250  batch loss =  3.8884 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   3260  batch loss =  3.8883 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3270  batch loss =  3.8879 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3280  batch loss =  3.8875 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3290  batch loss =  3.8878 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3300  batch loss =  3.8872 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   3310  batch loss =  3.8862 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3320  batch loss =  3.8854 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3330  batch loss =  3.8850 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3340  batch loss =  3.8854 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3350  batch loss =  3.8838 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3360  batch loss =  3.8851 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3370  batch loss =  3.8838 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   3380  batch loss =  3.8883 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3390  batch loss =  3.8823 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3400  batch loss =  3.8830 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3410  batch loss =  3.8827 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   3420  batch loss =  3.8821 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3430  batch loss =  3.8807 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3440  batch loss =  3.8817 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   3450  batch loss =  3.8806 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   3460  batch loss =  3.8805 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3470  batch loss =  3.8802 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3480  batch loss =  3.8792 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3490  batch loss =  3.8804 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3500  batch loss =  3.8798 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3510  batch loss =  3.8784 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3520  batch loss =  3.8780 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3530  batch loss =  3.8774 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3540  batch loss =  3.8781 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3550  batch loss =  3.8775 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3560  batch loss =  3.8781 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3570  batch loss =  3.8759 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3580  batch loss =  3.8758 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   3590  batch loss =  3.8750 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3600  batch loss =  3.8756 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3610  batch loss =  3.8738 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   3620  batch loss =  3.8743 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3630  batch loss =  3.8742 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3640  batch loss =  3.8739 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3650  batch loss =  3.8740 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   3660  batch loss =  3.8720 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3670  batch loss =  3.8725 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   3680  batch loss =  3.8715 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   3690  batch loss =  3.8709 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3700  batch loss =  3.8712 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3710  batch loss =  3.8715 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   3720  batch loss =  3.8700 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   3730  batch loss =  3.8705 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3740  batch loss =  3.8710 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3750  batch loss =  3.8689 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   3760  batch loss =  3.8688 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   3770  batch loss =  3.8682 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3780  batch loss =  3.8679 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   3790  batch loss =  3.8672 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3800  batch loss =  3.8667 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3810  batch loss =  3.8668 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   3820  batch loss =  3.8666 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3830  batch loss =  3.8657 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   3840  batch loss =  3.8653 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   3850  batch loss =  3.8655 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3860  batch loss =  3.8644 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   3870  batch loss =  3.8641 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   3880  batch loss =  3.8633 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3890  batch loss =  3.8638 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3900  batch loss =  3.8631 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   3910  batch loss =  3.8632 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3920  batch loss =  3.8618 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3930  batch loss =  3.8615 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   3940  batch loss =  3.8613 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3950  batch loss =  3.8612 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   3960  batch loss =  3.8603 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   3970  batch loss =  3.8596 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   3980  batch loss =  3.8598 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   3990  batch loss =  3.8593 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   4000  batch loss =  3.8586 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4010  batch loss =  3.8593 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4020  batch loss =  3.8587 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4030  batch loss =  3.8580 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4040  batch loss =  3.8570 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4050  batch loss =  3.8575 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   4060  batch loss =  3.8568 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   4070  batch loss =  3.8570 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   4080  batch loss =  3.8553 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4090  batch loss =  3.8561 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4100  batch loss =  3.8547 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4110  batch loss =  3.8542 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4120  batch loss =  3.8544 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   4130  batch loss =  3.8539 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4140  batch loss =  3.8533 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4150  batch loss =  3.8530 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4160  batch loss =  3.8539 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4170  batch loss =  3.8529 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4180  batch loss =  3.8524 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4190  batch loss =  3.8515 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   4200  batch loss =  3.8516 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4210  batch loss =  3.8508 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4220  batch loss =  3.8500 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4230  batch loss =  3.8506 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4240  batch loss =  3.8494 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   4250  batch loss =  3.8495 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4260  batch loss =  3.8494 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4270  batch loss =  3.8486 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4280  batch loss =  3.8478 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4290  batch loss =  3.8498 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   4300  batch loss =  3.8467 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4310  batch loss =  3.8467 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4320  batch loss =  3.8465 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4330  batch loss =  3.8454 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4340  batch loss =  3.8458 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4350  batch loss =  3.8452 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   4360  batch loss =  3.8444 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4370  batch loss =  3.8459 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4380  batch loss =  3.8451 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4390  batch loss =  3.8435 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4400  batch loss =  3.8424 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4410  batch loss =  3.8435 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4420  batch loss =  3.8427 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4430  batch loss =  3.8417 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   4440  batch loss =  3.8414 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4450  batch loss =  3.8418 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4460  batch loss =  3.8402 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4470  batch loss =  3.8401 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4480  batch loss =  3.8397 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4490  batch loss =  3.8396 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4500  batch loss =  3.8389 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   4510  batch loss =  3.8393 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4520  batch loss =  3.8394 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   4530  batch loss =  3.8385 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4540  batch loss =  3.8376 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4550  batch loss =  3.8370 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   4560  batch loss =  3.8376 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   4570  batch loss =  3.8379 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4580  batch loss =  3.8363 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4590  batch loss =  3.8362 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4600  batch loss =  3.8359 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4610  batch loss =  3.8351 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   4620  batch loss =  3.8342 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4630  batch loss =  3.8336 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4640  batch loss =  3.8339 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4650  batch loss =  3.8338 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   4660  batch loss =  3.8326 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   4670  batch loss =  3.8323 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4680  batch loss =  3.8328 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   4690  batch loss =  3.8324 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4700  batch loss =  3.8313 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   4710  batch loss =  3.8318 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   4720  batch loss =  3.8305 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4730  batch loss =  3.8312 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   4740  batch loss =  3.8310 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   4750  batch loss =  3.8295 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4760  batch loss =  3.8291 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   4770  batch loss =  3.8291 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4780  batch loss =  3.8284 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   4790  batch loss =  3.8293 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =   4800  batch loss =  3.8285 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4810  batch loss =  3.8269 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   4820  batch loss =  3.8276 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4830  batch loss =  3.8278 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4840  batch loss =  3.8260 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4850  batch loss =  3.8266 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   4860  batch loss =  3.8256 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   4870  batch loss =  3.8252 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   4880  batch loss =  3.8252 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4890  batch loss =  3.8243 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4900  batch loss =  3.8244 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   4910  batch loss =  3.8246 train accuracy = 89.64 dev accuracy = 91.20\n",
      "epoch =   4920  batch loss =  3.8240 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   4930  batch loss =  3.8232 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   4940  batch loss =  3.8224 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   4950  batch loss =  3.8230 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4960  batch loss =  3.8232 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   4970  batch loss =  3.8230 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4980  batch loss =  3.8211 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   4990  batch loss =  3.8213 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5000  batch loss =  3.8207 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5010  batch loss =  3.8200 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5020  batch loss =  3.8198 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5030  batch loss =  3.8196 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5040  batch loss =  3.8213 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5050  batch loss =  3.8187 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5060  batch loss =  3.8184 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5070  batch loss =  3.8186 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5080  batch loss =  3.8179 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5090  batch loss =  3.8179 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5100  batch loss =  3.8169 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5110  batch loss =  3.8176 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   5120  batch loss =  3.8165 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5130  batch loss =  3.8166 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5140  batch loss =  3.8166 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5150  batch loss =  3.8167 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   5160  batch loss =  3.8154 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5170  batch loss =  3.8151 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   5180  batch loss =  3.8153 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5190  batch loss =  3.8147 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5200  batch loss =  3.8146 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5210  batch loss =  3.8137 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5220  batch loss =  3.8143 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5230  batch loss =  3.8137 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5240  batch loss =  3.8129 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5250  batch loss =  3.8129 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   5260  batch loss =  3.8124 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5270  batch loss =  3.8121 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5280  batch loss =  3.8116 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   5290  batch loss =  3.8114 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5300  batch loss =  3.8111 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5310  batch loss =  3.8112 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5320  batch loss =  3.8111 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5330  batch loss =  3.8102 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   5340  batch loss =  3.8105 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   5350  batch loss =  3.8103 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5360  batch loss =  3.8092 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5370  batch loss =  3.8103 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   5380  batch loss =  3.8090 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   5390  batch loss =  3.8091 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5400  batch loss =  3.8085 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   5410  batch loss =  3.8086 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5420  batch loss =  3.8081 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5430  batch loss =  3.8071 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   5440  batch loss =  3.8073 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5450  batch loss =  3.8072 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5460  batch loss =  3.8067 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   5470  batch loss =  3.8066 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   5480  batch loss =  3.8055 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   5490  batch loss =  3.8057 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5500  batch loss =  3.8060 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   5510  batch loss =  3.8052 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5520  batch loss =  3.8037 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5530  batch loss =  3.8041 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5540  batch loss =  3.8039 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5550  batch loss =  3.8035 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5560  batch loss =  3.8031 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5570  batch loss =  3.8042 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   5580  batch loss =  3.8032 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5590  batch loss =  3.8043 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5600  batch loss =  3.8019 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5610  batch loss =  3.8024 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5620  batch loss =  3.8019 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5630  batch loss =  3.8017 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5640  batch loss =  3.8023 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5650  batch loss =  3.8017 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5660  batch loss =  3.8009 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   5670  batch loss =  3.8009 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5680  batch loss =  3.8002 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5690  batch loss =  3.8002 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   5700  batch loss =  3.7994 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5710  batch loss =  3.8001 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   5720  batch loss =  3.7989 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5730  batch loss =  3.7995 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5740  batch loss =  3.7993 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   5750  batch loss =  3.7991 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   5760  batch loss =  3.7997 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   5770  batch loss =  3.7983 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5780  batch loss =  3.7985 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5790  batch loss =  3.7978 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5800  batch loss =  3.7978 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   5810  batch loss =  3.7976 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   5820  batch loss =  3.7974 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5830  batch loss =  3.7968 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5840  batch loss =  3.7966 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5850  batch loss =  3.7976 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   5860  batch loss =  3.7965 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5870  batch loss =  3.7956 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5880  batch loss =  3.7951 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5890  batch loss =  3.7959 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5900  batch loss =  3.7959 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   5910  batch loss =  3.7944 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   5920  batch loss =  3.7944 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   5930  batch loss =  3.7941 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   5940  batch loss =  3.7957 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5950  batch loss =  3.7947 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   5960  batch loss =  3.7943 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   5970  batch loss =  3.7935 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   5980  batch loss =  3.7934 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   5990  batch loss =  3.7938 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   6000  batch loss =  3.7927 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   6010  batch loss =  3.7925 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   6020  batch loss =  3.7928 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   6030  batch loss =  3.7931 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   6040  batch loss =  3.7938 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6050  batch loss =  3.7918 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6060  batch loss =  3.7919 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   6070  batch loss =  3.7915 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6080  batch loss =  3.7921 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6090  batch loss =  3.7912 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6100  batch loss =  3.7917 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6110  batch loss =  3.7915 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   6120  batch loss =  3.7920 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6130  batch loss =  3.7904 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6140  batch loss =  3.7898 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6150  batch loss =  3.7896 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6160  batch loss =  3.7892 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6170  batch loss =  3.7890 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6180  batch loss =  3.7892 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6190  batch loss =  3.7892 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   6200  batch loss =  3.7893 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6210  batch loss =  3.7888 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6220  batch loss =  3.7892 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   6230  batch loss =  3.7884 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6240  batch loss =  3.7890 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6250  batch loss =  3.7880 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6260  batch loss =  3.7879 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6270  batch loss =  3.7881 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6280  batch loss =  3.7873 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6290  batch loss =  3.7875 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6300  batch loss =  3.7867 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   6310  batch loss =  3.7871 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6320  batch loss =  3.7868 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6330  batch loss =  3.7862 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   6340  batch loss =  3.7865 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6350  batch loss =  3.7865 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6360  batch loss =  3.7862 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   6370  batch loss =  3.7859 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6380  batch loss =  3.7858 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   6390  batch loss =  3.7865 train accuracy = 89.64 dev accuracy = 91.20\n",
      "epoch =   6400  batch loss =  3.7857 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   6410  batch loss =  3.7851 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   6420  batch loss =  3.7850 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6430  batch loss =  3.7859 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   6440  batch loss =  3.7847 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6450  batch loss =  3.7841 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6460  batch loss =  3.7846 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   6470  batch loss =  3.7842 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6480  batch loss =  3.7839 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   6490  batch loss =  3.7841 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6500  batch loss =  3.7834 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6510  batch loss =  3.7837 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6520  batch loss =  3.7834 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6530  batch loss =  3.7824 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   6540  batch loss =  3.7834 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6550  batch loss =  3.7829 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6560  batch loss =  3.7826 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6570  batch loss =  3.7838 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6580  batch loss =  3.7834 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   6590  batch loss =  3.7836 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6600  batch loss =  3.7820 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   6610  batch loss =  3.7819 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   6620  batch loss =  3.7821 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6630  batch loss =  3.7822 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6640  batch loss =  3.7813 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   6650  batch loss =  3.7814 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   6660  batch loss =  3.7818 train accuracy = 89.60 dev accuracy = 91.20\n",
      "epoch =   6670  batch loss =  3.7822 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   6680  batch loss =  3.7818 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6690  batch loss =  3.7817 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   6700  batch loss =  3.7807 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6710  batch loss =  3.7804 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6720  batch loss =  3.7804 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6730  batch loss =  3.7804 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6740  batch loss =  3.7804 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6750  batch loss =  3.7801 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6760  batch loss =  3.7796 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   6770  batch loss =  3.7799 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   6780  batch loss =  3.7806 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   6790  batch loss =  3.7797 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6800  batch loss =  3.7798 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6810  batch loss =  3.7798 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6820  batch loss =  3.7789 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6830  batch loss =  3.7787 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6840  batch loss =  3.7794 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6850  batch loss =  3.7789 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   6860  batch loss =  3.7787 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   6870  batch loss =  3.7782 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6880  batch loss =  3.7784 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   6890  batch loss =  3.7796 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   6900  batch loss =  3.7784 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6910  batch loss =  3.7784 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6920  batch loss =  3.7788 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   6930  batch loss =  3.7777 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6940  batch loss =  3.7774 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6950  batch loss =  3.7781 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   6960  batch loss =  3.7777 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   6970  batch loss =  3.7773 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   6980  batch loss =  3.7776 train accuracy = 89.64 dev accuracy = 91.20\n",
      "epoch =   6990  batch loss =  3.7784 train accuracy = 89.64 dev accuracy = 91.20\n",
      "epoch =   7000  batch loss =  3.7773 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7010  batch loss =  3.7767 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7020  batch loss =  3.7772 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7030  batch loss =  3.7768 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7040  batch loss =  3.7759 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7050  batch loss =  3.7764 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7060  batch loss =  3.7764 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7070  batch loss =  3.7760 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7080  batch loss =  3.7766 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   7090  batch loss =  3.7766 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7100  batch loss =  3.7761 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7110  batch loss =  3.7761 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7120  batch loss =  3.7759 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7130  batch loss =  3.7753 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7140  batch loss =  3.7757 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   7150  batch loss =  3.7755 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7160  batch loss =  3.7754 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7170  batch loss =  3.7749 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   7180  batch loss =  3.7747 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7190  batch loss =  3.7754 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7200  batch loss =  3.7747 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7210  batch loss =  3.7747 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7220  batch loss =  3.7752 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   7230  batch loss =  3.7751 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7240  batch loss =  3.7745 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7250  batch loss =  3.7749 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7260  batch loss =  3.7737 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7270  batch loss =  3.7741 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7280  batch loss =  3.7749 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7290  batch loss =  3.7739 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   7300  batch loss =  3.7748 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   7310  batch loss =  3.7738 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7320  batch loss =  3.7738 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7330  batch loss =  3.7740 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7340  batch loss =  3.7748 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7350  batch loss =  3.7736 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7360  batch loss =  3.7735 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7370  batch loss =  3.7738 train accuracy = 89.60 dev accuracy = 91.20\n",
      "epoch =   7380  batch loss =  3.7734 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7390  batch loss =  3.7734 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7400  batch loss =  3.7723 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7410  batch loss =  3.7745 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7420  batch loss =  3.7728 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7430  batch loss =  3.7723 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7440  batch loss =  3.7730 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7450  batch loss =  3.7731 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7460  batch loss =  3.7721 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7470  batch loss =  3.7721 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   7480  batch loss =  3.7725 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7490  batch loss =  3.7723 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7500  batch loss =  3.7722 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7510  batch loss =  3.7723 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   7520  batch loss =  3.7721 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7530  batch loss =  3.7713 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   7540  batch loss =  3.7711 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7550  batch loss =  3.7711 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7560  batch loss =  3.7712 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7570  batch loss =  3.7718 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7580  batch loss =  3.7713 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7590  batch loss =  3.7711 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   7600  batch loss =  3.7712 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7610  batch loss =  3.7710 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7620  batch loss =  3.7710 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7630  batch loss =  3.7715 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   7640  batch loss =  3.7706 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7650  batch loss =  3.7714 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   7660  batch loss =  3.7706 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7670  batch loss =  3.7702 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   7680  batch loss =  3.7709 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7690  batch loss =  3.7707 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7700  batch loss =  3.7705 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   7710  batch loss =  3.7701 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7720  batch loss =  3.7699 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7730  batch loss =  3.7700 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7740  batch loss =  3.7697 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7750  batch loss =  3.7700 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   7760  batch loss =  3.7694 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7770  batch loss =  3.7695 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7780  batch loss =  3.7699 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7790  batch loss =  3.7699 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7800  batch loss =  3.7695 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7810  batch loss =  3.7693 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7820  batch loss =  3.7703 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7830  batch loss =  3.7691 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7840  batch loss =  3.7707 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   7850  batch loss =  3.7701 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7860  batch loss =  3.7691 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7870  batch loss =  3.7694 train accuracy = 89.56 dev accuracy = 91.20\n",
      "epoch =   7880  batch loss =  3.7692 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   7890  batch loss =  3.7696 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7900  batch loss =  3.7694 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7910  batch loss =  3.7688 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7920  batch loss =  3.7694 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   7930  batch loss =  3.7687 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   7940  batch loss =  3.7688 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7950  batch loss =  3.7699 train accuracy = 89.60 dev accuracy = 91.20\n",
      "epoch =   7960  batch loss =  3.7689 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   7970  batch loss =  3.7692 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7980  batch loss =  3.7690 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   7990  batch loss =  3.7684 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8000  batch loss =  3.7681 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8010  batch loss =  3.7682 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   8020  batch loss =  3.7675 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8030  batch loss =  3.7679 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8040  batch loss =  3.7680 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   8050  batch loss =  3.7678 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   8060  batch loss =  3.7680 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8070  batch loss =  3.7681 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   8080  batch loss =  3.7679 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8090  batch loss =  3.7681 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   8100  batch loss =  3.7673 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8110  batch loss =  3.7673 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8120  batch loss =  3.7670 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   8130  batch loss =  3.7675 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8140  batch loss =  3.7673 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8150  batch loss =  3.7672 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   8160  batch loss =  3.7673 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8170  batch loss =  3.7665 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8180  batch loss =  3.7666 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8190  batch loss =  3.7663 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8200  batch loss =  3.7670 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8210  batch loss =  3.7670 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8220  batch loss =  3.7674 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   8230  batch loss =  3.7664 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   8240  batch loss =  3.7673 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8250  batch loss =  3.7668 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8260  batch loss =  3.7681 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8270  batch loss =  3.7666 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8280  batch loss =  3.7662 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8290  batch loss =  3.7678 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8300  batch loss =  3.7664 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8310  batch loss =  3.7664 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   8320  batch loss =  3.7660 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8330  batch loss =  3.7654 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   8340  batch loss =  3.7660 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   8350  batch loss =  3.7671 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8360  batch loss =  3.7660 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   8370  batch loss =  3.7665 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8380  batch loss =  3.7658 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8390  batch loss =  3.7659 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8400  batch loss =  3.7656 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8410  batch loss =  3.7652 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8420  batch loss =  3.7653 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8430  batch loss =  3.7661 train accuracy = 89.60 dev accuracy = 91.20\n",
      "epoch =   8440  batch loss =  3.7654 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8450  batch loss =  3.7649 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8460  batch loss =  3.7651 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8470  batch loss =  3.7659 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8480  batch loss =  3.7652 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8490  batch loss =  3.7653 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   8500  batch loss =  3.7652 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8510  batch loss =  3.7651 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8520  batch loss =  3.7657 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8530  batch loss =  3.7651 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8540  batch loss =  3.7653 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8550  batch loss =  3.7650 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8560  batch loss =  3.7643 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8570  batch loss =  3.7642 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8580  batch loss =  3.7645 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8590  batch loss =  3.7659 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   8600  batch loss =  3.7653 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   8610  batch loss =  3.7644 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   8620  batch loss =  3.7637 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8630  batch loss =  3.7645 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   8640  batch loss =  3.7642 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   8650  batch loss =  3.7642 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   8660  batch loss =  3.7642 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8670  batch loss =  3.7639 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8680  batch loss =  3.7639 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8690  batch loss =  3.7643 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   8700  batch loss =  3.7649 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8710  batch loss =  3.7642 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8720  batch loss =  3.7637 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8730  batch loss =  3.7639 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8740  batch loss =  3.7634 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8750  batch loss =  3.7631 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8760  batch loss =  3.7632 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   8770  batch loss =  3.7642 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8780  batch loss =  3.7637 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   8790  batch loss =  3.7633 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8800  batch loss =  3.7634 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   8810  batch loss =  3.7637 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   8820  batch loss =  3.7638 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   8830  batch loss =  3.7634 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   8840  batch loss =  3.7629 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   8850  batch loss =  3.7637 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8860  batch loss =  3.7628 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   8870  batch loss =  3.7624 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8880  batch loss =  3.7625 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8890  batch loss =  3.7626 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   8900  batch loss =  3.7622 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   8910  batch loss =  3.7628 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8920  batch loss =  3.7622 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8930  batch loss =  3.7627 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   8940  batch loss =  3.7630 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   8950  batch loss =  3.7627 train accuracy = 89.64 dev accuracy = 91.20\n",
      "epoch =   8960  batch loss =  3.7628 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   8970  batch loss =  3.7634 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   8980  batch loss =  3.7625 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   8990  batch loss =  3.7628 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9000  batch loss =  3.7619 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9010  batch loss =  3.7630 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9020  batch loss =  3.7624 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   9030  batch loss =  3.7620 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9040  batch loss =  3.7619 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   9050  batch loss =  3.7625 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   9060  batch loss =  3.7619 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   9070  batch loss =  3.7624 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9080  batch loss =  3.7629 train accuracy = 89.60 dev accuracy = 91.20\n",
      "epoch =   9090  batch loss =  3.7622 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9100  batch loss =  3.7622 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9110  batch loss =  3.7611 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9120  batch loss =  3.7622 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9130  batch loss =  3.7615 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9140  batch loss =  3.7616 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9150  batch loss =  3.7616 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9160  batch loss =  3.7625 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9170  batch loss =  3.7612 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9180  batch loss =  3.7617 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9190  batch loss =  3.7607 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9200  batch loss =  3.7616 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9210  batch loss =  3.7621 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9220  batch loss =  3.7611 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9230  batch loss =  3.7617 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9240  batch loss =  3.7606 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   9250  batch loss =  3.7612 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9260  batch loss =  3.7611 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9270  batch loss =  3.7609 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9280  batch loss =  3.7608 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9290  batch loss =  3.7610 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9300  batch loss =  3.7613 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9310  batch loss =  3.7613 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9320  batch loss =  3.7607 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9330  batch loss =  3.7608 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9340  batch loss =  3.7615 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9350  batch loss =  3.7606 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9360  batch loss =  3.7609 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   9370  batch loss =  3.7607 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9380  batch loss =  3.7611 train accuracy = 89.64 dev accuracy = 91.00\n",
      "epoch =   9390  batch loss =  3.7602 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9400  batch loss =  3.7604 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9410  batch loss =  3.7598 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9420  batch loss =  3.7600 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9430  batch loss =  3.7601 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9440  batch loss =  3.7608 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   9450  batch loss =  3.7603 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9460  batch loss =  3.7612 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   9470  batch loss =  3.7600 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   9480  batch loss =  3.7610 train accuracy = 89.64 dev accuracy = 91.10\n",
      "epoch =   9490  batch loss =  3.7596 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9500  batch loss =  3.7603 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   9510  batch loss =  3.7601 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9520  batch loss =  3.7605 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   9530  batch loss =  3.7594 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9540  batch loss =  3.7599 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9550  batch loss =  3.7597 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9560  batch loss =  3.7595 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9570  batch loss =  3.7596 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9580  batch loss =  3.7596 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9590  batch loss =  3.7608 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =   9600  batch loss =  3.7596 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9610  batch loss =  3.7593 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =   9620  batch loss =  3.7594 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9630  batch loss =  3.7593 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   9640  batch loss =  3.7594 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9650  batch loss =  3.7595 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9660  batch loss =  3.7599 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =   9670  batch loss =  3.7597 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   9680  batch loss =  3.7591 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9690  batch loss =  3.7591 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   9700  batch loss =  3.7586 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   9710  batch loss =  3.7592 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9720  batch loss =  3.7587 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9730  batch loss =  3.7593 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9740  batch loss =  3.7595 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9750  batch loss =  3.7593 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9760  batch loss =  3.7601 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9770  batch loss =  3.7591 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =   9780  batch loss =  3.7586 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9790  batch loss =  3.7582 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9800  batch loss =  3.7581 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9810  batch loss =  3.7586 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =   9820  batch loss =  3.7585 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9830  batch loss =  3.7583 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9840  batch loss =  3.7583 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9850  batch loss =  3.7586 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9860  batch loss =  3.7587 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9870  batch loss =  3.7590 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   9880  batch loss =  3.7594 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9890  batch loss =  3.7576 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9900  batch loss =  3.7579 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9910  batch loss =  3.7583 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =   9920  batch loss =  3.7582 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =   9930  batch loss =  3.7579 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =   9940  batch loss =  3.7585 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   9950  batch loss =  3.7579 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9960  batch loss =  3.7588 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =   9970  batch loss =  3.7585 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =   9980  batch loss =  3.7578 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =   9990  batch loss =  3.7585 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10000  batch loss =  3.7582 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =  10010  batch loss =  3.7582 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =  10020  batch loss =  3.7583 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10030  batch loss =  3.7585 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10040  batch loss =  3.7577 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10050  batch loss =  3.7586 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10060  batch loss =  3.7580 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =  10070  batch loss =  3.7588 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =  10080  batch loss =  3.7579 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10090  batch loss =  3.7580 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =  10100  batch loss =  3.7571 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10110  batch loss =  3.7575 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10120  batch loss =  3.7576 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  10130  batch loss =  3.7582 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =  10140  batch loss =  3.7574 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10150  batch loss =  3.7578 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10160  batch loss =  3.7573 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10170  batch loss =  3.7571 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10180  batch loss =  3.7574 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  10190  batch loss =  3.7573 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10200  batch loss =  3.7584 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =  10210  batch loss =  3.7577 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  10220  batch loss =  3.7577 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10230  batch loss =  3.7579 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10240  batch loss =  3.7567 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10250  batch loss =  3.7570 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10260  batch loss =  3.7570 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10270  batch loss =  3.7569 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =  10280  batch loss =  3.7570 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  10290  batch loss =  3.7570 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10300  batch loss =  3.7574 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10310  batch loss =  3.7571 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  10320  batch loss =  3.7579 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10330  batch loss =  3.7571 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10340  batch loss =  3.7569 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =  10350  batch loss =  3.7570 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =  10360  batch loss =  3.7571 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10370  batch loss =  3.7576 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10380  batch loss =  3.7567 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10390  batch loss =  3.7577 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =  10400  batch loss =  3.7570 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10410  batch loss =  3.7570 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  10420  batch loss =  3.7573 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10430  batch loss =  3.7565 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  10440  batch loss =  3.7569 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  10450  batch loss =  3.7573 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10460  batch loss =  3.7567 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10470  batch loss =  3.7568 train accuracy = 89.76 dev accuracy = 91.30\n",
      "epoch =  10480  batch loss =  3.7564 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10490  batch loss =  3.7568 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10500  batch loss =  3.7577 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  10510  batch loss =  3.7569 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10520  batch loss =  3.7564 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10530  batch loss =  3.7563 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10540  batch loss =  3.7559 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10550  batch loss =  3.7565 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10560  batch loss =  3.7572 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10570  batch loss =  3.7564 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10580  batch loss =  3.7563 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10590  batch loss =  3.7562 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10600  batch loss =  3.7562 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10610  batch loss =  3.7564 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10620  batch loss =  3.7560 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  10630  batch loss =  3.7562 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10640  batch loss =  3.7564 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10650  batch loss =  3.7561 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10660  batch loss =  3.7570 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10670  batch loss =  3.7558 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10680  batch loss =  3.7562 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10690  batch loss =  3.7560 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10700  batch loss =  3.7558 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10710  batch loss =  3.7560 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10720  batch loss =  3.7556 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10730  batch loss =  3.7564 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10740  batch loss =  3.7559 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10750  batch loss =  3.7565 train accuracy = 89.60 dev accuracy = 91.00\n",
      "epoch =  10760  batch loss =  3.7558 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10770  batch loss =  3.7558 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  10780  batch loss =  3.7561 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10790  batch loss =  3.7562 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10800  batch loss =  3.7556 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  10810  batch loss =  3.7558 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10820  batch loss =  3.7553 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  10830  batch loss =  3.7554 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  10840  batch loss =  3.7553 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  10850  batch loss =  3.7560 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10860  batch loss =  3.7559 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10870  batch loss =  3.7552 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10880  batch loss =  3.7556 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10890  batch loss =  3.7559 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10900  batch loss =  3.7553 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  10910  batch loss =  3.7552 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  10920  batch loss =  3.7557 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10930  batch loss =  3.7549 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10940  batch loss =  3.7557 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  10950  batch loss =  3.7554 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  10960  batch loss =  3.7552 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10970  batch loss =  3.7550 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  10980  batch loss =  3.7549 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  10990  batch loss =  3.7556 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11000  batch loss =  3.7550 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11010  batch loss =  3.7558 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  11020  batch loss =  3.7545 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11030  batch loss =  3.7548 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  11040  batch loss =  3.7552 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  11050  batch loss =  3.7557 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  11060  batch loss =  3.7554 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11070  batch loss =  3.7548 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11080  batch loss =  3.7549 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11090  batch loss =  3.7550 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  11100  batch loss =  3.7548 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11110  batch loss =  3.7544 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  11120  batch loss =  3.7551 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11130  batch loss =  3.7550 train accuracy = 89.72 dev accuracy = 91.00\n",
      "epoch =  11140  batch loss =  3.7545 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11150  batch loss =  3.7549 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11160  batch loss =  3.7551 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  11170  batch loss =  3.7556 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11180  batch loss =  3.7547 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  11190  batch loss =  3.7550 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11200  batch loss =  3.7541 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  11210  batch loss =  3.7546 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11220  batch loss =  3.7540 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11230  batch loss =  3.7548 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11240  batch loss =  3.7550 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11250  batch loss =  3.7540 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11260  batch loss =  3.7551 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11270  batch loss =  3.7545 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11280  batch loss =  3.7546 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11290  batch loss =  3.7543 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11300  batch loss =  3.7548 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  11310  batch loss =  3.7544 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  11320  batch loss =  3.7541 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11330  batch loss =  3.7541 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11340  batch loss =  3.7543 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11350  batch loss =  3.7542 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11360  batch loss =  3.7538 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11370  batch loss =  3.7539 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11380  batch loss =  3.7549 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11390  batch loss =  3.7547 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11400  batch loss =  3.7541 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  11410  batch loss =  3.7550 train accuracy = 89.60 dev accuracy = 91.10\n",
      "epoch =  11420  batch loss =  3.7533 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  11430  batch loss =  3.7541 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  11440  batch loss =  3.7545 train accuracy = 89.80 dev accuracy = 91.20\n",
      "epoch =  11450  batch loss =  3.7549 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11460  batch loss =  3.7537 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  11470  batch loss =  3.7548 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11480  batch loss =  3.7545 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11490  batch loss =  3.7544 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  11500  batch loss =  3.7536 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11510  batch loss =  3.7538 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11520  batch loss =  3.7538 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  11530  batch loss =  3.7535 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  11540  batch loss =  3.7538 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11550  batch loss =  3.7541 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11560  batch loss =  3.7536 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11570  batch loss =  3.7532 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11580  batch loss =  3.7552 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11590  batch loss =  3.7539 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11600  batch loss =  3.7537 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11610  batch loss =  3.7543 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  11620  batch loss =  3.7533 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11630  batch loss =  3.7537 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11640  batch loss =  3.7534 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  11650  batch loss =  3.7534 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11660  batch loss =  3.7533 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11670  batch loss =  3.7535 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11680  batch loss =  3.7531 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11690  batch loss =  3.7533 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  11700  batch loss =  3.7533 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11710  batch loss =  3.7533 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11720  batch loss =  3.7530 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  11730  batch loss =  3.7535 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11740  batch loss =  3.7530 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11750  batch loss =  3.7532 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11760  batch loss =  3.7534 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11770  batch loss =  3.7536 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  11780  batch loss =  3.7537 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11790  batch loss =  3.7531 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11800  batch loss =  3.7531 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  11810  batch loss =  3.7535 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11820  batch loss =  3.7531 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11830  batch loss =  3.7537 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  11840  batch loss =  3.7537 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  11850  batch loss =  3.7538 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11860  batch loss =  3.7533 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11870  batch loss =  3.7531 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11880  batch loss =  3.7530 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11890  batch loss =  3.7536 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  11900  batch loss =  3.7529 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11910  batch loss =  3.7538 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  11920  batch loss =  3.7530 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11930  batch loss =  3.7534 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11940  batch loss =  3.7535 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11950  batch loss =  3.7530 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  11960  batch loss =  3.7528 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11970  batch loss =  3.7531 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  11980  batch loss =  3.7529 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  11990  batch loss =  3.7531 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12000  batch loss =  3.7529 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12010  batch loss =  3.7524 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  12020  batch loss =  3.7537 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12030  batch loss =  3.7531 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  12040  batch loss =  3.7532 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12050  batch loss =  3.7533 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12060  batch loss =  3.7527 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12070  batch loss =  3.7524 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  12080  batch loss =  3.7525 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12090  batch loss =  3.7528 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12100  batch loss =  3.7528 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12110  batch loss =  3.7531 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12120  batch loss =  3.7530 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12130  batch loss =  3.7532 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12140  batch loss =  3.7524 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12150  batch loss =  3.7531 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12160  batch loss =  3.7523 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12170  batch loss =  3.7536 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12180  batch loss =  3.7534 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12190  batch loss =  3.7521 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12200  batch loss =  3.7528 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  12210  batch loss =  3.7527 train accuracy = 89.80 dev accuracy = 91.30\n",
      "epoch =  12220  batch loss =  3.7523 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12230  batch loss =  3.7525 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12240  batch loss =  3.7529 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12250  batch loss =  3.7525 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12260  batch loss =  3.7522 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12270  batch loss =  3.7519 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12280  batch loss =  3.7539 train accuracy = 89.76 dev accuracy = 91.20\n",
      "epoch =  12290  batch loss =  3.7522 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12300  batch loss =  3.7519 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12310  batch loss =  3.7519 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12320  batch loss =  3.7523 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  12330  batch loss =  3.7526 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12340  batch loss =  3.7518 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12350  batch loss =  3.7519 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12360  batch loss =  3.7525 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12370  batch loss =  3.7519 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12380  batch loss =  3.7528 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12390  batch loss =  3.7517 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12400  batch loss =  3.7529 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12410  batch loss =  3.7519 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12420  batch loss =  3.7521 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12430  batch loss =  3.7518 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12440  batch loss =  3.7533 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12450  batch loss =  3.7529 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12460  batch loss =  3.7523 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12470  batch loss =  3.7521 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12480  batch loss =  3.7524 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12490  batch loss =  3.7518 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12500  batch loss =  3.7531 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12510  batch loss =  3.7524 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12520  batch loss =  3.7518 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12530  batch loss =  3.7526 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12540  batch loss =  3.7517 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12550  batch loss =  3.7521 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12560  batch loss =  3.7518 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12570  batch loss =  3.7526 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12580  batch loss =  3.7519 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  12590  batch loss =  3.7519 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  12600  batch loss =  3.7527 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12610  batch loss =  3.7515 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12620  batch loss =  3.7524 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12630  batch loss =  3.7522 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12640  batch loss =  3.7523 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12650  batch loss =  3.7525 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12660  batch loss =  3.7514 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12670  batch loss =  3.7522 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12680  batch loss =  3.7515 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12690  batch loss =  3.7516 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12700  batch loss =  3.7517 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12710  batch loss =  3.7516 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12720  batch loss =  3.7524 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12730  batch loss =  3.7522 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12740  batch loss =  3.7515 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12750  batch loss =  3.7526 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  12760  batch loss =  3.7525 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12770  batch loss =  3.7517 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12780  batch loss =  3.7516 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12790  batch loss =  3.7514 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12800  batch loss =  3.7516 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12810  batch loss =  3.7513 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12820  batch loss =  3.7514 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12830  batch loss =  3.7516 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12840  batch loss =  3.7517 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12850  batch loss =  3.7518 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12860  batch loss =  3.7517 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12870  batch loss =  3.7512 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12880  batch loss =  3.7516 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12890  batch loss =  3.7523 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12900  batch loss =  3.7517 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12910  batch loss =  3.7515 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12920  batch loss =  3.7512 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12930  batch loss =  3.7520 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  12940  batch loss =  3.7512 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  12950  batch loss =  3.7518 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  12960  batch loss =  3.7513 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12970  batch loss =  3.7511 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12980  batch loss =  3.7515 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  12990  batch loss =  3.7509 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13000  batch loss =  3.7518 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13010  batch loss =  3.7520 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13020  batch loss =  3.7517 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13030  batch loss =  3.7508 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13040  batch loss =  3.7510 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13050  batch loss =  3.7511 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13060  batch loss =  3.7517 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13070  batch loss =  3.7514 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13080  batch loss =  3.7509 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13090  batch loss =  3.7512 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13100  batch loss =  3.7509 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13110  batch loss =  3.7506 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13120  batch loss =  3.7509 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13130  batch loss =  3.7511 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13140  batch loss =  3.7511 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13150  batch loss =  3.7513 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13160  batch loss =  3.7510 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13170  batch loss =  3.7509 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13180  batch loss =  3.7510 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13190  batch loss =  3.7506 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13200  batch loss =  3.7513 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13210  batch loss =  3.7508 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13220  batch loss =  3.7511 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  13230  batch loss =  3.7510 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13240  batch loss =  3.7511 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13250  batch loss =  3.7505 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13260  batch loss =  3.7509 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13270  batch loss =  3.7509 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13280  batch loss =  3.7516 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  13290  batch loss =  3.7513 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13300  batch loss =  3.7510 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13310  batch loss =  3.7511 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13320  batch loss =  3.7506 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13330  batch loss =  3.7507 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13340  batch loss =  3.7503 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13350  batch loss =  3.7508 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13360  batch loss =  3.7513 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13370  batch loss =  3.7509 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13380  batch loss =  3.7510 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13390  batch loss =  3.7504 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13400  batch loss =  3.7507 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13410  batch loss =  3.7508 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13420  batch loss =  3.7513 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13430  batch loss =  3.7504 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13440  batch loss =  3.7507 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13450  batch loss =  3.7506 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13460  batch loss =  3.7512 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13470  batch loss =  3.7510 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13480  batch loss =  3.7504 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13490  batch loss =  3.7507 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13500  batch loss =  3.7506 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13510  batch loss =  3.7506 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13520  batch loss =  3.7509 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13530  batch loss =  3.7508 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13540  batch loss =  3.7505 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13550  batch loss =  3.7507 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13560  batch loss =  3.7501 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13570  batch loss =  3.7507 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13580  batch loss =  3.7522 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13590  batch loss =  3.7514 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13600  batch loss =  3.7504 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13610  batch loss =  3.7504 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13620  batch loss =  3.7505 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13630  batch loss =  3.7503 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13640  batch loss =  3.7503 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13650  batch loss =  3.7507 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13660  batch loss =  3.7506 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13670  batch loss =  3.7508 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13680  batch loss =  3.7505 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13690  batch loss =  3.7501 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  13700  batch loss =  3.7502 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13710  batch loss =  3.7503 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13720  batch loss =  3.7506 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13730  batch loss =  3.7514 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  13740  batch loss =  3.7503 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13750  batch loss =  3.7499 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13760  batch loss =  3.7506 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13770  batch loss =  3.7508 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13780  batch loss =  3.7514 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13790  batch loss =  3.7505 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13800  batch loss =  3.7498 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13810  batch loss =  3.7506 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13820  batch loss =  3.7504 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13830  batch loss =  3.7502 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  13840  batch loss =  3.7506 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13850  batch loss =  3.7503 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  13860  batch loss =  3.7506 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13870  batch loss =  3.7509 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13880  batch loss =  3.7498 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13890  batch loss =  3.7507 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13900  batch loss =  3.7504 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13910  batch loss =  3.7502 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13920  batch loss =  3.7501 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13930  batch loss =  3.7517 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13940  batch loss =  3.7507 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13950  batch loss =  3.7501 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  13960  batch loss =  3.7499 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  13970  batch loss =  3.7503 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  13980  batch loss =  3.7507 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  13990  batch loss =  3.7499 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14000  batch loss =  3.7504 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14010  batch loss =  3.7497 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14020  batch loss =  3.7500 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14030  batch loss =  3.7501 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14040  batch loss =  3.7507 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14050  batch loss =  3.7495 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14060  batch loss =  3.7520 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14070  batch loss =  3.7510 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14080  batch loss =  3.7515 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  14090  batch loss =  3.7504 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14100  batch loss =  3.7504 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14110  batch loss =  3.7503 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14120  batch loss =  3.7497 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14130  batch loss =  3.7504 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  14140  batch loss =  3.7506 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  14150  batch loss =  3.7495 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14160  batch loss =  3.7502 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  14170  batch loss =  3.7497 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14180  batch loss =  3.7498 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14190  batch loss =  3.7502 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14200  batch loss =  3.7498 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14210  batch loss =  3.7498 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14220  batch loss =  3.7501 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14230  batch loss =  3.7503 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14240  batch loss =  3.7509 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14250  batch loss =  3.7498 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14260  batch loss =  3.7497 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14270  batch loss =  3.7493 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14280  batch loss =  3.7494 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14290  batch loss =  3.7494 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14300  batch loss =  3.7507 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  14310  batch loss =  3.7499 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14320  batch loss =  3.7495 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14330  batch loss =  3.7500 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14340  batch loss =  3.7507 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14350  batch loss =  3.7497 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14360  batch loss =  3.7501 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14370  batch loss =  3.7493 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14380  batch loss =  3.7499 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14390  batch loss =  3.7498 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14400  batch loss =  3.7503 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14410  batch loss =  3.7494 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14420  batch loss =  3.7500 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14430  batch loss =  3.7500 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14440  batch loss =  3.7500 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14450  batch loss =  3.7498 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14460  batch loss =  3.7497 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  14470  batch loss =  3.7498 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14480  batch loss =  3.7498 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14490  batch loss =  3.7492 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14500  batch loss =  3.7498 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  14510  batch loss =  3.7492 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  14520  batch loss =  3.7501 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14530  batch loss =  3.7493 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14540  batch loss =  3.7500 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14550  batch loss =  3.7489 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14560  batch loss =  3.7500 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  14570  batch loss =  3.7496 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14580  batch loss =  3.7501 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  14590  batch loss =  3.7496 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14600  batch loss =  3.7492 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14610  batch loss =  3.7491 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14620  batch loss =  3.7497 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14630  batch loss =  3.7509 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14640  batch loss =  3.7507 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14650  batch loss =  3.7493 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  14660  batch loss =  3.7491 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14670  batch loss =  3.7492 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14680  batch loss =  3.7490 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14690  batch loss =  3.7501 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14700  batch loss =  3.7490 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14710  batch loss =  3.7494 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14720  batch loss =  3.7501 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14730  batch loss =  3.7500 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14740  batch loss =  3.7499 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14750  batch loss =  3.7495 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14760  batch loss =  3.7496 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14770  batch loss =  3.7497 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14780  batch loss =  3.7492 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  14790  batch loss =  3.7493 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  14800  batch loss =  3.7492 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14810  batch loss =  3.7490 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14820  batch loss =  3.7495 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14830  batch loss =  3.7495 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14840  batch loss =  3.7493 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  14850  batch loss =  3.7498 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14860  batch loss =  3.7494 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  14870  batch loss =  3.7494 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14880  batch loss =  3.7492 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14890  batch loss =  3.7493 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14900  batch loss =  3.7501 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  14910  batch loss =  3.7492 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  14920  batch loss =  3.7497 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14930  batch loss =  3.7488 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  14940  batch loss =  3.7500 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14950  batch loss =  3.7492 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14960  batch loss =  3.7492 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  14970  batch loss =  3.7487 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  14980  batch loss =  3.7494 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  14990  batch loss =  3.7487 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  15000  batch loss =  3.7495 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15010  batch loss =  3.7490 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15020  batch loss =  3.7485 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15030  batch loss =  3.7489 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15040  batch loss =  3.7486 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15050  batch loss =  3.7495 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15060  batch loss =  3.7489 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15070  batch loss =  3.7489 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15080  batch loss =  3.7497 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15090  batch loss =  3.7489 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15100  batch loss =  3.7497 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15110  batch loss =  3.7494 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15120  batch loss =  3.7489 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15130  batch loss =  3.7492 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  15140  batch loss =  3.7492 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15150  batch loss =  3.7495 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15160  batch loss =  3.7494 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15170  batch loss =  3.7484 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15180  batch loss =  3.7491 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15190  batch loss =  3.7491 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  15200  batch loss =  3.7491 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  15210  batch loss =  3.7487 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15220  batch loss =  3.7486 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15230  batch loss =  3.7488 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  15240  batch loss =  3.7485 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15250  batch loss =  3.7487 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15260  batch loss =  3.7495 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15270  batch loss =  3.7498 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15280  batch loss =  3.7488 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15290  batch loss =  3.7488 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  15300  batch loss =  3.7490 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15310  batch loss =  3.7491 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15320  batch loss =  3.7486 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15330  batch loss =  3.7498 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15340  batch loss =  3.7487 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15350  batch loss =  3.7486 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15360  batch loss =  3.7485 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15370  batch loss =  3.7496 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15380  batch loss =  3.7490 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15390  batch loss =  3.7488 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15400  batch loss =  3.7485 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  15410  batch loss =  3.7489 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  15420  batch loss =  3.7489 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  15430  batch loss =  3.7488 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15440  batch loss =  3.7488 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15450  batch loss =  3.7497 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  15460  batch loss =  3.7489 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15470  batch loss =  3.7489 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15480  batch loss =  3.7484 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  15490  batch loss =  3.7493 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15500  batch loss =  3.7493 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  15510  batch loss =  3.7491 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  15520  batch loss =  3.7491 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15530  batch loss =  3.7496 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15540  batch loss =  3.7485 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15550  batch loss =  3.7485 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15560  batch loss =  3.7486 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15570  batch loss =  3.7484 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  15580  batch loss =  3.7489 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15590  batch loss =  3.7485 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15600  batch loss =  3.7483 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15610  batch loss =  3.7487 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15620  batch loss =  3.7482 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15630  batch loss =  3.7488 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15640  batch loss =  3.7484 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  15650  batch loss =  3.7489 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15660  batch loss =  3.7490 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15670  batch loss =  3.7487 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  15680  batch loss =  3.7490 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15690  batch loss =  3.7487 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15700  batch loss =  3.7486 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  15710  batch loss =  3.7490 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15720  batch loss =  3.7498 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  15730  batch loss =  3.7485 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15740  batch loss =  3.7486 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15750  batch loss =  3.7491 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15760  batch loss =  3.7486 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15770  batch loss =  3.7490 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  15780  batch loss =  3.7493 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15790  batch loss =  3.7481 train accuracy = 90.00 dev accuracy = 90.90\n",
      "epoch =  15800  batch loss =  3.7481 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15810  batch loss =  3.7489 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  15820  batch loss =  3.7491 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  15830  batch loss =  3.7483 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15840  batch loss =  3.7485 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15850  batch loss =  3.7482 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15860  batch loss =  3.7490 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15870  batch loss =  3.7484 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  15880  batch loss =  3.7493 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  15890  batch loss =  3.7484 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  15900  batch loss =  3.7488 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15910  batch loss =  3.7490 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15920  batch loss =  3.7487 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15930  batch loss =  3.7483 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  15940  batch loss =  3.7490 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  15950  batch loss =  3.7484 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15960  batch loss =  3.7489 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  15970  batch loss =  3.7496 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15980  batch loss =  3.7478 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  15990  batch loss =  3.7484 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16000  batch loss =  3.7488 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16010  batch loss =  3.7484 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16020  batch loss =  3.7495 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16030  batch loss =  3.7488 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16040  batch loss =  3.7486 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16050  batch loss =  3.7478 train accuracy = 89.96 dev accuracy = 91.20\n",
      "epoch =  16060  batch loss =  3.7484 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16070  batch loss =  3.7489 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  16080  batch loss =  3.7489 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  16090  batch loss =  3.7488 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  16100  batch loss =  3.7482 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16110  batch loss =  3.7488 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16120  batch loss =  3.7483 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16130  batch loss =  3.7483 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16140  batch loss =  3.7488 train accuracy = 90.00 dev accuracy = 90.90\n",
      "epoch =  16150  batch loss =  3.7479 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16160  batch loss =  3.7484 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16170  batch loss =  3.7481 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16180  batch loss =  3.7502 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16190  batch loss =  3.7483 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16200  batch loss =  3.7483 train accuracy = 90.04 dev accuracy = 90.90\n",
      "epoch =  16210  batch loss =  3.7480 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16220  batch loss =  3.7478 train accuracy = 90.04 dev accuracy = 90.90\n",
      "epoch =  16230  batch loss =  3.7481 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16240  batch loss =  3.7479 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16250  batch loss =  3.7484 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16260  batch loss =  3.7483 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16270  batch loss =  3.7480 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16280  batch loss =  3.7480 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16290  batch loss =  3.7492 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16300  batch loss =  3.7480 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  16310  batch loss =  3.7486 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16320  batch loss =  3.7485 train accuracy = 90.12 dev accuracy = 90.80\n",
      "epoch =  16330  batch loss =  3.7487 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16340  batch loss =  3.7481 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16350  batch loss =  3.7482 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16360  batch loss =  3.7480 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16370  batch loss =  3.7492 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16380  batch loss =  3.7483 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16390  batch loss =  3.7480 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16400  batch loss =  3.7483 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16410  batch loss =  3.7483 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16420  batch loss =  3.7480 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16430  batch loss =  3.7481 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16440  batch loss =  3.7482 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16450  batch loss =  3.7479 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16460  batch loss =  3.7478 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  16470  batch loss =  3.7489 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  16480  batch loss =  3.7491 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  16490  batch loss =  3.7481 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16500  batch loss =  3.7484 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16510  batch loss =  3.7485 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16520  batch loss =  3.7490 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  16530  batch loss =  3.7479 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  16540  batch loss =  3.7482 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16550  batch loss =  3.7478 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16560  batch loss =  3.7482 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16570  batch loss =  3.7477 train accuracy = 89.96 dev accuracy = 91.20\n",
      "epoch =  16580  batch loss =  3.7481 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16590  batch loss =  3.7477 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  16600  batch loss =  3.7483 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16610  batch loss =  3.7474 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  16620  batch loss =  3.7484 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  16630  batch loss =  3.7478 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16640  batch loss =  3.7479 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16650  batch loss =  3.7482 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16660  batch loss =  3.7483 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  16670  batch loss =  3.7482 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16680  batch loss =  3.7479 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16690  batch loss =  3.7476 train accuracy = 89.96 dev accuracy = 91.20\n",
      "epoch =  16700  batch loss =  3.7480 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16710  batch loss =  3.7484 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  16720  batch loss =  3.7485 train accuracy = 89.72 dev accuracy = 91.10\n",
      "epoch =  16730  batch loss =  3.7476 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16740  batch loss =  3.7484 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16750  batch loss =  3.7482 train accuracy = 90.04 dev accuracy = 90.90\n",
      "epoch =  16760  batch loss =  3.7477 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16770  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  16780  batch loss =  3.7480 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16790  batch loss =  3.7481 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16800  batch loss =  3.7475 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  16810  batch loss =  3.7480 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16820  batch loss =  3.7476 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16830  batch loss =  3.7486 train accuracy = 90.00 dev accuracy = 91.10\n",
      "epoch =  16840  batch loss =  3.7476 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16850  batch loss =  3.7481 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16860  batch loss =  3.7482 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16870  batch loss =  3.7478 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  16880  batch loss =  3.7481 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  16890  batch loss =  3.7490 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  16900  batch loss =  3.7480 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16910  batch loss =  3.7480 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  16920  batch loss =  3.7479 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16930  batch loss =  3.7479 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  16940  batch loss =  3.7479 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  16950  batch loss =  3.7477 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  16960  batch loss =  3.7481 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16970  batch loss =  3.7481 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16980  batch loss =  3.7475 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  16990  batch loss =  3.7485 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  17000  batch loss =  3.7490 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  17010  batch loss =  3.7476 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  17020  batch loss =  3.7478 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  17030  batch loss =  3.7483 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  17040  batch loss =  3.7481 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  17050  batch loss =  3.7479 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  17060  batch loss =  3.7482 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17070  batch loss =  3.7485 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17080  batch loss =  3.7488 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17090  batch loss =  3.7485 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17100  batch loss =  3.7476 train accuracy = 90.00 dev accuracy = 91.10\n",
      "epoch =  17110  batch loss =  3.7474 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17120  batch loss =  3.7478 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17130  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17140  batch loss =  3.7478 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  17150  batch loss =  3.7474 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17160  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17170  batch loss =  3.7473 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  17180  batch loss =  3.7476 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17190  batch loss =  3.7476 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  17200  batch loss =  3.7479 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17210  batch loss =  3.7484 train accuracy = 89.68 dev accuracy = 91.10\n",
      "epoch =  17220  batch loss =  3.7479 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17230  batch loss =  3.7480 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  17240  batch loss =  3.7477 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17250  batch loss =  3.7481 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17260  batch loss =  3.7473 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17270  batch loss =  3.7487 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  17280  batch loss =  3.7480 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17290  batch loss =  3.7475 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17300  batch loss =  3.7482 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17310  batch loss =  3.7477 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17320  batch loss =  3.7474 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17330  batch loss =  3.7473 train accuracy = 90.04 dev accuracy = 90.90\n",
      "epoch =  17340  batch loss =  3.7481 train accuracy = 89.80 dev accuracy = 91.10\n",
      "epoch =  17350  batch loss =  3.7480 train accuracy = 90.12 dev accuracy = 90.80\n",
      "epoch =  17360  batch loss =  3.7477 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17370  batch loss =  3.7477 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17380  batch loss =  3.7478 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17390  batch loss =  3.7474 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17400  batch loss =  3.7482 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17410  batch loss =  3.7480 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17420  batch loss =  3.7479 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  17430  batch loss =  3.7476 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17440  batch loss =  3.7480 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  17450  batch loss =  3.7484 train accuracy = 90.00 dev accuracy = 90.90\n",
      "epoch =  17460  batch loss =  3.7478 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17470  batch loss =  3.7479 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17480  batch loss =  3.7473 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17490  batch loss =  3.7473 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17500  batch loss =  3.7480 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17510  batch loss =  3.7474 train accuracy = 90.04 dev accuracy = 90.90\n",
      "epoch =  17520  batch loss =  3.7470 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17530  batch loss =  3.7478 train accuracy = 90.12 dev accuracy = 90.80\n",
      "epoch =  17540  batch loss =  3.7480 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17550  batch loss =  3.7481 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17560  batch loss =  3.7474 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17570  batch loss =  3.7478 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17580  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17590  batch loss =  3.7475 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17600  batch loss =  3.7479 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17610  batch loss =  3.7475 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17620  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17630  batch loss =  3.7481 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17640  batch loss =  3.7485 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  17650  batch loss =  3.7475 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17660  batch loss =  3.7484 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17670  batch loss =  3.7477 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17680  batch loss =  3.7475 train accuracy = 90.16 dev accuracy = 90.80\n",
      "epoch =  17690  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17700  batch loss =  3.7477 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17710  batch loss =  3.7474 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17720  batch loss =  3.7478 train accuracy = 90.04 dev accuracy = 90.90\n",
      "epoch =  17730  batch loss =  3.7471 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17740  batch loss =  3.7477 train accuracy = 90.04 dev accuracy = 90.90\n",
      "epoch =  17750  batch loss =  3.7476 train accuracy = 89.84 dev accuracy = 91.10\n",
      "epoch =  17760  batch loss =  3.7481 train accuracy = 89.76 dev accuracy = 91.10\n",
      "epoch =  17770  batch loss =  3.7474 train accuracy = 90.16 dev accuracy = 90.80\n",
      "epoch =  17780  batch loss =  3.7470 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17790  batch loss =  3.7481 train accuracy = 90.12 dev accuracy = 90.80\n",
      "epoch =  17800  batch loss =  3.7470 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17810  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17820  batch loss =  3.7477 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  17830  batch loss =  3.7468 train accuracy = 89.96 dev accuracy = 91.20\n",
      "epoch =  17840  batch loss =  3.7474 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  17850  batch loss =  3.7478 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17860  batch loss =  3.7469 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17870  batch loss =  3.7478 train accuracy = 90.12 dev accuracy = 90.80\n",
      "epoch =  17880  batch loss =  3.7478 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17890  batch loss =  3.7475 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  17900  batch loss =  3.7483 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17910  batch loss =  3.7472 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17920  batch loss =  3.7479 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  17930  batch loss =  3.7471 train accuracy = 90.04 dev accuracy = 91.10\n",
      "epoch =  17940  batch loss =  3.7473 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  17950  batch loss =  3.7483 train accuracy = 90.08 dev accuracy = 90.80\n",
      "epoch =  17960  batch loss =  3.7478 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  17970  batch loss =  3.7472 train accuracy = 90.12 dev accuracy = 90.80\n",
      "epoch =  17980  batch loss =  3.7476 train accuracy = 89.96 dev accuracy = 91.20\n",
      "epoch =  17990  batch loss =  3.7473 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  18000  batch loss =  3.7478 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  18010  batch loss =  3.7473 train accuracy = 89.96 dev accuracy = 91.20\n",
      "epoch =  18020  batch loss =  3.7477 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  18030  batch loss =  3.7473 train accuracy = 89.96 dev accuracy = 91.10\n",
      "epoch =  18040  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  18050  batch loss =  3.7472 train accuracy = 90.16 dev accuracy = 90.80\n",
      "epoch =  18060  batch loss =  3.7474 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  18070  batch loss =  3.7469 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  18080  batch loss =  3.7476 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  18090  batch loss =  3.7480 train accuracy = 89.92 dev accuracy = 91.10\n",
      "epoch =  18100  batch loss =  3.7468 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  18110  batch loss =  3.7477 train accuracy = 90.04 dev accuracy = 90.90\n",
      "epoch =  18120  batch loss =  3.7481 train accuracy = 89.88 dev accuracy = 91.10\n",
      "epoch =  18130  batch loss =  3.7474 train accuracy = 90.00 dev accuracy = 90.80\n",
      "epoch =  18140  batch loss =  3.7473 train accuracy = 89.96 dev accuracy = 91.20\n",
      "epoch =  18150  batch loss =  3.7478 train accuracy = 90.04 dev accuracy = 90.80\n",
      "epoch =  18160  batch loss =  3.7474 train accuracy = 90.04 dev accuracy = 91.00\n",
      "epoch =  18170  batch loss =  3.7477 train accuracy = 90.12 dev accuracy = 90.80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Files\\PRML\\Assignment 4\\test_ann copy.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/PRML/Assignment%204/test_ann%20copy.ipynb#ch0000006?line=17'>18</a>\u001b[0m     loss_obj \u001b[39m=\u001b[39m loss_func(oupt, Y1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/PRML/Assignment%204/test_ann%20copy.ipynb#ch0000006?line=18'>19</a>\u001b[0m     loss_obj\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Files/PRML/Assignment%204/test_ann%20copy.ipynb#ch0000006?line=19'>20</a>\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_obj\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/PRML/Assignment%204/test_ann%20copy.ipynb#ch0000006?line=20'>21</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/PRML/Assignment%204/test_ann%20copy.ipynb#ch0000006?line=21'>22</a>\u001b[0m \u001b[39m# loss /= batcher.num_items\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in pbar(range(max_epochs)):\n",
    "    loss = 0.\n",
    "    if epoch > 0 and epoch % (10) == 0:\n",
    "        print('epoch = %6d' % epoch, end='')\n",
    "        print('  batch loss = %7.4f' % np.average(losses[-10:]), end='')\n",
    "        acc = akkuracy(net, X, Y)\n",
    "        print(' train accuracy = %0.2f' % acc, end='')\n",
    "        acc = akkuracy(net, X_dev, Y_dev)\n",
    "        print(' dev accuracy = %0.2f' % acc)\n",
    "    for curr_bat in batcher:\n",
    "        X1 = T.Tensor(X[curr_bat]).cuda()\n",
    "        Y1 = T.Tensor(Y[curr_bat]).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        oupt = net(X1)\n",
    "        # print(oupt)\n",
    "        # print(Y1)\n",
    "        loss_obj = loss_func(oupt, Y1)\n",
    "        loss_obj.backward()\n",
    "        loss += loss_obj.item()\n",
    "        optimizer.step()\n",
    "    # loss /= batcher.num_items\n",
    "    losses.append(loss)\n",
    "    if(loss < 0.001):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y,X_orig, model, steps=1000, cmap='Paired'):\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "\n",
    "    # Define region of interest by data limits\n",
    "    xmin, xmax = X_orig[:,0].min() - 1, X_orig[:,0].max() + 1\n",
    "    ymin, ymax = X_orig[:,1].min() - 1, X_orig[:,1].max() + 1\n",
    "    steps = 1000\n",
    "    x_span = np.linspace(xmin, xmax, steps)\n",
    "    y_span = np.linspace(ymin, ymax, steps)\n",
    "    xx, yy = np.meshgrid(x_span, y_span)\n",
    "\n",
    "    # Make predictions across region of interest\n",
    "    # xx = PredictorScaler.transform(xx)\n",
    "    # yy = PredictorScaler.transform(yy)\n",
    "    # t = PredictorScaler.transform(np.c_[xx.ravel(), yy.ravel()])\n",
    "    t = np.c_[xx.ravel(), yy.ravel()]\n",
    "    # transformer = FDA(t,)\n",
    "    labels = model.forward(T.Tensor(t).cuda()).cpu().detach().numpy()\n",
    "\n",
    "    # hard labels\n",
    "    labels_h_ind_1 = np.where(labels > 0.5)\n",
    "    labels_h_ind_0 = np.where(labels <= 0.5)\n",
    "    labels_h = np.zeros(labels.shape)\n",
    "    labels_h[labels_h_ind_1] = 1\n",
    "    labels_h[labels_h_ind_0] = 0\n",
    "\n",
    "    # Plot decision boundary in region of interest\n",
    "    z = labels_h.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n",
    "\n",
    "    # Get predicted labels on training data and plot\n",
    "    # train_labels = model.predict(X)\n",
    "    ax.scatter(X_orig[:,0], X_orig[:,1], c=y, cmap=cmap, lw=0)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 432x288 with 1 Axes>, <AxesSubplot:>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_dev_orig = PredictorScaler.inverse_transform(X_dev)\n",
    "plot_decision_boundary(X_dev, Y_dev,X_dev, net, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94ae5e5b5ae5a1ee57a607c9497711b6bf7cc4fc8b73b07c0408939ea9c64789"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
